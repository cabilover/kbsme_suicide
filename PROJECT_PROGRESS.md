# KBSMC 자살 예측 프로젝트 진행 상황

## 프로젝트 개요
- **프로젝트명**: 개인별 정신 건강 지표 기반 자살 예측 모델 개발
- **목표**: 연간 정신 건강 데이터를 활용하여 다음 해의 불안/우울/수면 점수 및 자살 사고/시도 예측
- **데이터 규모**: 약 150만 행, 269,339명의 개인 데이터
- **기간**: 2015-2024 (10년간)

## 현재 진행 상황

### ✅ 2025-01-XX 기준 최신 업데이트: 모델별 데이터 검증 최적화 및 평가 로직 중앙화
- **모델별 `_validate_input_data` 메서드 오버라이드**: 각 모델의 특성에 맞는 데이터 검증 구현
  - XGBoost: 범주형 변수를 숫자로 변환 (XGBoost 호환성)
  - CatBoost/LightGBM/Random Forest: 범주형 변수 보존 (모델 자체 처리)
- **평가 로직 중앙화**: `evaluation.py`의 `calculate_all_metrics`가 모든 평가의 단일 진입점
- **복잡한 컬럼 매칭 개선**: 전처리 후 컬럼명 변경(`remainder__`, `pass__`, `num__`, `cat__` 접두사)에도 안정적 매칭
- **설정 기반 타겟 타입 정의**: 하드코딩된 로직 대신 `configs/base/common.yaml`의 `target_types` 섹션에서 명시적 정의
- **타겟별 메트릭 구조**: 평면화된 메트릭에서 타겟별 구조화된 메트릭으로 개선
- **코드 구조 개선**: 중복 제거, 책임 분리, 유지보수성 향상

### ✅ 2025-06-25 기준 최신 업데이트: 숫자 검증 유틸리티 함수 추가
- **새로운 유틸리티 함수 추가**: `src/utils.py`에 `safe_float_conversion()`, `is_valid_number()` 함수 추가
- **하이퍼파라미터 튜닝 안정성 향상**: Optuna 튜닝 과정에서 숫자 변환 및 검증을 통한 안전한 처리
- **데이터 품질 보장**: NaN/Inf 값 자동 감지 및 처리로 튜닝 과정의 안정성 향상
- **코드 품질 개선**: 하이퍼파라미터 튜닝 과정에서 발생할 수 있는 숫자 관련 오류 방지

### ✅ 2025-06-24 기준 최신 실험 결과 반영
- XGBoost, CatBoost, LightGBM, Random Forest 4개 모델 모두 ConfigManager 기반 하이퍼파라미터 튜닝 및 전체 파이프라인 정상 동작 확인
- **nrows 옵션을 통한 부분 데이터 실험 정상 동작 확인**
- **타겟 컬럼 매칭 로직 개선**: 전처리 후 컬럼명 변경(pass__, num__, cat__ 접두사)에도 모든 모델에서 타겟 인식 및 학습/예측 정상 동작
- **분류/회귀 자동 분기 개선**: 모든 모델에서 타겟 타입에 따라 자동으로 분류/회귀 파라미터 적용
  - LightGBM: binary/binary_logloss (분류), regression/rmse (회귀)
  - Random Forest: gini (분류), mse (회귀)
- **모델별 파라미터 처리 최적화**: 
  - LightGBM: focal_loss 파라미터 제거, 타겟 접두사 처리
  - Random Forest: sample_weight 분리, 분류/회귀별 파라미터 필터링
- **MLflow 기록 정상화**: 모든 모델에서 파라미터, 메트릭, 아티팩트 정상 기록 확인
- **극단적 불균형 데이터(자살 시도 0.12%)로 인해 F1-score 등 주요 분류 성능은 0.0에 수렴(모델 구조/파이프라인 문제 아님)**
- **nrows 옵션 미지정 시 전체 데이터 사용, 지정 시 부분 데이터만 사용**
- 실험 결과, 파이프라인/모델 구조/MLflow 연동/결과 저장 등 모든 시스템이 안정적으로 동작
- 다음 단계로 리샘플링, 평가 지표 개선, 앙상블, 고급 피처 엔지니어링 등 실험 예정

### ✅ 완료된 단계: Phase 5-1 데이터 분석 및 전처리

#### 1. 데이터 로딩 및 기본 정보
- **데이터 크기**: 1,569,071 행 × 15 열
- **개인 수**: 269,339명
- **기간**: 2015년 1월 2일 ~ 2024년 12월 31일
- **컬럼 구성**:
  - 식별자: `id`, `yov`(진료연도), `dov`(진료일자)
  - 인구학적 정보: `age`, `sex`
  - 정신 건강 점수: `comp`, `anxiety_score`, `depress_score`, `sleep_score`
  - 자살 관련: `suicide_t`(사고), `suicide_a`(시도), `suicide_c`(성공), `suicide_y`(자살자)
  - 분류: `psychia_cate`, `check`

#### 2. 결측치 분석 결과
| 컬럼 | 결측치 수 | 결측률(%) | 처리 방안 |
|------|-----------|-----------|-----------|
| `check` | 1,569,050 | 99.999 | 제외 (미사용 컬럼) |
| `suicide_c` | 1,568,875 | 99.988 | 제외 (미사용 컬럼) |
| `suicide_y` | 1,568,875 | 99.988 | 제외 (미사용 컬럼) |
| `sleep_score` | 1,411 | 0.090 | 전처리 시 보간 필요 |
| `depress_score` | 300 | 0.019 | 전처리 시 보간 필요 |
| `suicide_t` | 175 | 0.011 | 전처리 시 보간 필요 |
| `suicide_a` | 159 | 0.010 | 전처리 시 보간 필요 |
| `anxiety_score` | 58 | 0.004 | 전처리 시 보간 필요 |

#### 3. 이상치 분석 결과
| 변수 | 이상치 수 | 이상치 비율(%) | 정상 범위 |
|------|-----------|----------------|-----------|
| `comp` | 229,495 | 14.63 | [-1.00, 7.00] |
| `depress_score` | 83,421 | 5.25 | [-11.00, 21.00] |
| `anxiety_score` | 48,213 | 3.07 | [-21.00, 35.00] |
| `sleep_score` | 39,105 | 2.49 | [-1.50, 10.50] |

#### 4. 시계열 길이 분석
- **평균 시계열 길이**: 5.79년
- **중앙값**: 6년
- **범위**: 1-10년
- **분포**: 
  - 25%: 2년 이하
  - 50%: 6년
  - 75%: 9년

#### 5. 타겟 변수 분포 분석

##### 연속형 변수 (점수)
| 변수 | 평균 | 표준편차 | 최소값 | 최대값 | 분포 특성 |
|------|------|----------|--------|--------|-----------|
| `anxiety_score` | 8.75 | 10.80 | 0 | 80 | 우편향, 많은 0값 |
| `depress_score` | 6.48 | 7.45 | -1 | 60 | 우편향 |
| `sleep_score` | 4.34 | 2.55 | 0 | 21 | 정규분포에 가까움 |

##### 이진형 변수 (자살 관련)
| 변수 | 0 (부정) | 1 (긍정) | 불균형 비율 |
|------|----------|----------|-------------|
| `suicide_t` (자살 사고) | 96.60% | 3.40% | 28:1 |
| `suicide_a` (자살 시도) | 99.88% | 0.12% | 849:1 |

#### 6. 타겟 변수 생성 결과
- **생성된 타겟**: `*_next_year` (다음 해 예측값)
- **가용 데이터 비율**: 약 82.8%
- **총 예측 가능 레코드**: 약 130만 건

#### 7. 피처 엔지니어링 완료
- **시간 기반 피처**: `month`, `day_of_week`, `day_of_year`
- **과거 이력 피처**: 
  - `*_rolling_mean_2y`: 2년 이동평균
  - `*_rolling_std_2y`: 2년 이동표준편차
  - `*_yoy_change`: 전년 대비 변화량

## 생성된 파일 구조

```
data/
├── sourcedata/
│   └── data.csv                    # 원본 데이터
├── sourcedata_analysis/
│   ├── figures/                    # 분석 그래프 (7개 PNG 파일)
│   │   ├── missing_values_analysis.png
│   │   ├── time_series_length_analysis.png
│   │   ├── anxiety_score_distribution_analysis.png
│   │   ├── depress_score_distribution_analysis.png
│   │   ├── sleep_score_distribution_analysis.png
│   │   ├── suicide_t_distribution_analysis.png
│   │   └── suicide_a_distribution_analysis.png
│   └── reports/                    # 분석 리포트 (6개 TXT 파일)
│       ├── missing_values_analysis.txt
│       ├── outlier_analysis.txt
│       ├── time_series_length_stats.txt
│       ├── data_type_analysis.txt
│       ├── target_variable_analysis.txt
│       └── feature_engineering_analysis.txt
└── processed/
    └── processed_data_with_features.csv  # 전처리 완료 데이터 (250MB)
```

## 주요 발견사항 및 도전과제

### 1. 데이터 품질 이슈
- **높은 불균형**: 자살 시도는 0.12%로 극도로 불균형
- **이상치 존재**: 특히 `comp` 변수에서 14.63% 이상치
- **결측치**: 일부 변수에서 소량의 결측치 존재

### 2. 시계열 특성
- **개인별 변동성**: 시계열 길이가 1-10년으로 다양
- **충분한 데이터**: 평균 5.79년으로 예측에 적절한 길이

### 3. 예측 가능성
- **타겟 가용성**: 82.8%의 레코드에서 다음 해 예측 가능
- **피처 풍부성**: 시간 기반 + 과거 이력 피처로 충분한 정보 제공

### ✅ 완료된 단계: Phase 5-2 기준 모델 구축 및 ML 파이프라인 개발

#### 1. 실험 관리 시스템 및 분할 파이프라인 구축
- **실험 관리 시스템**: `src/splits.py`와 `scripts/run_hyperparameter_tuning.py`로 구현
- **설정 관리**: 계층적 config 체계에서 일관적으로 관리하며, 전략별 파라미터를 한 곳에서 쉽게 전환 가능
- **MLflow 연동**: 실험별, 폴드별, 전략별 결과를 체계적으로 기록 및 추적

#### 2. 구현된 분할 전략 및 테스트 결과
- **ID 기반 최종 테스트 세트 분리**: GroupShuffleSplit을 활용해 train/val과 test의 ID가 절대 겹치지 않도록 분리. 테스트 세트는 오직 최종 평가에만 사용되며, 교차 검증 및 모델 개발 과정에서는 사용하지 않음.
- **다양한 교차 검증 전략 지원 및 검증**
    - `time_series_walk_forward`: 연도별로 과거 데이터를 누적 학습, 미래 연도 검증. 각 폴드 내에서도 ID 기반 분할 적용.
    - `time_series_group_kfold`: ID와 시간 순서를 모두 고려한 K-Fold. 각 폴드 내에서 ID가 겹치지 않으면서, 검증 데이터는 항상 훈련 데이터보다 미래 시점만 포함.
    - `group_kfold`: 순수하게 ID만 기준으로 폴드를 나누는 전략. 시간 순서는 보장하지 않음.
- **모든 전략에 대해 10,000행 샘플 데이터로 실험**
    - 각 전략별로 폴드 수, 훈련/검증 샘플 수, ID 수, 연도 범위 등 상세 정보가 로그 및 MLflow에 기록됨.
    - MLflow의 nested run 기능을 활용해 각 폴드별 실행을 별도로 관리, 폴드별 메트릭과 요약을 JSON 아티팩트로 저장.
    - 테스트 세트 정보도 별도 아티팩트로 저장하여, 실험 과정에서의 데이터 유출 가능성을 완전히 차단.

#### 3. ML 파이프라인 모듈 구현
- **전처리 모듈** (`src/preprocessing.py`): 
  - 시계열 보간 (개인별 ffill/bfill)
  - 수치형/범주형 결측치 처리
  - OrdinalEncoder 기반 범주형 인코딩
  - XGBoost 호환을 위한 float32 변환
- **피처 엔지니어링 모듈** (`src/feature_engineering.py`):
  - 기존 피처 데이터 유출 검증
  - 시간 기반 피처 생성
  - 전처리된 컬럼명 처리 (`remainder__` 접두사)
- **XGBoost 모델 클래스** (`src/models/xgboost_model.py`):
  - 다중 출력 회귀/분류 지원
  - Early Stopping 구현 (XGBoost 1.7.6 호환)
  - 불균형 처리 (scale_pos_weight 자동 계산)
  - 피처 중요도 추출
- **훈련 모듈** (`src/training.py`):
  - 교차 검증 루프
  - 폴드별 전처리 파이프라인 학습
  - 최고 성능 모델 추적 및 저장
  - MLflow 로깅
- **평가 모듈** (`src/evaluation.py`):
  - 회귀/분류 지표 계산
  - 결과 시각화 및 요약

#### 4. 성공적인 파이프라인 테스트
- **600행 샘플 데이터로 전체 파이프라인 테스트 완료**
- **5개 폴드 교차 검증 성공**: 모든 폴드에서 모델 학습 및 예측 정상 동작
- **데이터 유출 방지**: 각 폴드별로 전처리 파이프라인 재학습
- **MLflow 로깅**: 실험 파라미터, 폴드별 메트릭, 모델 아티팩트 저장

#### 5. 주요 기술적 개선사항
- **XGBoost 호환성**: early_stopping_rounds 파라미터 처리 개선
- **데이터 타입 처리**: object 컬럼 자동 제외 및 float32 변환
- **결측치 처리**: NaN/inf 값 자동 제거
- **컬럼명 처리**: 전처리 후 `remainder__` 접두사 컬럼명 올바른 처리

### ✅ 완료된 단계: Phase 5-3 불균형 데이터 처리 및 평가 기능 통합

#### 1. 불균형 데이터 처리 및 실험 파이프라인 개선
- **클래스 가중치, scale_pos_weight**: XGBoost 등에서 불균형 데이터 처리를 위한 가중치 옵션 지원
- **실험 결과**: 불균형 데이터 처리 옵션 활성화 시에도 파이프라인 전체가 정상 동작하며, 실험 및 튜닝 결과가 MLflow에 일관되게 기록됨

## 현재 프로젝트 상태: Phase 5-4 진행 중 ✅

**Phase 5-4 (고급 모델 개발 및 확장)** 주요 작업이 완료되었습니다.

### ✅ 완료된 작업 (2025-06-25 기준)
- **숫자 검증 유틸리티 함수 추가**: 하이퍼파라미터 튜닝 과정의 안정성 향상
- **모든 고급 모델 구현 완료**: CatBoost, LightGBM, Random Forest 모델 클래스 구현 및 테스트 완료
- **ConfigManager 기반 리샘플링 비교 실험**: 계층적 config 시스템을 활용한 리샘플링 기법 비교 및 하이퍼파라미터 튜닝 통합 완성
- **MLflow 중첩 실행 문제 해결**: 리샘플링 비교 실험에서 MLflow run 충돌 방지

### 🔄 진행 중인 작업
- **앙상블 모델 개발**: Stacking, Blending, Voting 기법 구현 및 테스트

### 📋 예정된 작업
- **피처 엔지니어링 고도화**: 고급 피처 생성 및 선택 기법 적용
- **모델 해석 및 설명 가능성**: SHAP, LIME 등을 활용한 모델 해석 기능 추가
- **성능 최적화**: 메모리 사용량 및 실행 시간 최적화

## 기술적 환경

### 사용된 라이브러리
- **데이터 처리**: pandas, numpy
- **시각화**: matplotlib, seaborn
- **실험 관리**: mlflow
- **기계학습**: scikit-learn, xgboost==1.7.6, catboost, lightgbm (버전 고정)
- **하이퍼파라미터 튜닝**: optuna

### 환경 설정
- **Conda 환경**: simcare
- **Python 버전**: 3.10.18
- **경고 처리**: 특정 경고만 억제하여 중요한 이슈 포착

## 참고사항

### 파일 명명 규칙
- **분석 결과**: `sourcedata_analysis/` 폴더에 저장
- **전처리 데이터**: `processed/` 폴더에 저장
- **리포트 파일**: `.txt` 확장자 사용 (CSV 포맷)

### 코드 품질
- **PEP 8 준수**: 팀 컨벤션에 따른 코드 스타일
- **모듈화**: 기능별 함수 분리
- **문서화**: 각 함수에 독스트링 작성
- **안정성**: XGBoost 버전 호환성 및 파라미터 전달 안정화

---

**최종 업데이트**: 2025년 06월 24일
**작성자**: AI Assistant
**프로젝트 상태**: Phase 5-4 진행 중 ✅ (4개 모델 완료, ConfigManager 기반 리샘플링 비교 실험 완료, 앙상블 모델 개발 예정) 

## 2025-06-24 실험 및 디버깅 현황

- CatBoost, XGBoost, LightGBM, Random Forest 모두에서 타겟 컬럼 매칭, 데이터 타입, 메트릭 계산 등 구조적 문제는 해결됨
- 극도로 불균형한 데이터 특성상 모든 예측이 0이거나, 성능이 0에 수렴
- 하이퍼파라미터 튜닝(n_trials=5)에서 `ufunc 'isnan' not supported for the input types` 에러가 반복적으로 발생
    - score/metric이 float이 아닐 때 np.isnan, np.isinf 호출 시 발생
    - 안전한 float 변환 및 타입 체크 로직을 추가했으나, 일부 trial에서 여전히 발생
- 최종 모델 학습 시 타겟 컬럼 매칭 문제는 해결됨

### TODO (내일)
- isnan 에러가 발생하는 trial의 score/metric 타입 및 값을 추가로 로깅하여 원인 파악
- score가 float이 아닐 때 무조건 0.0으로 대체하는 로직을 한 번 더 점검
- 필요시 isnan/isinf 체크 자체를 try/except로 감싸서 완전 방지
- 불균형 데이터 처리(리샘플링, 클래스 가중치 등)는 구조적 문제 완전 해결 후 진행 