# 리샘플링 실험 및 하이퍼파라미터 튜닝 통합 설정 파일
# 불균형 데이터 처리를 위한 다양한 리샘플링 기법 테스트 및 최적화

# 기본 설정 파일 참조
base_config: "configs/default_config.yaml"

# 기본 설정 오버라이드
override_base_config:
  enabled: true
  
  # 리샘플링 활성화
  resampling:
    enabled: true
    method: "smote"  # "smote", "borderline_smote", "adasyn", "under_sampling", "hybrid"
    random_state: 42
    
    # SMOTE 설정
    smote_k_neighbors: 5
    
    # Borderline SMOTE 설정
    borderline_smote_k_neighbors: 5
    
    # ADASYN 설정
    adasyn_k_neighbors: 5
    
    # 언더샘플링 설정
    under_sampling_strategy: "random"  # "random", "tomek", "enn"
    
    # 하이브리드 샘플링 설정
    hybrid_strategy: "smote_tomek"  # "smote_tomek", "smote_enn"
    
    # 시계열 특화 설정
    time_series_adapted:
      enabled: false
      time_weight: 0.3
      pattern_preservation: true

# 하이퍼파라미터 튜닝 설정
tuning:
  # 최적화 방향
  direction: "maximize"  # "maximize" 또는 "minimize"
  
  # 튜닝 횟수 (리샘플링 기법별로 실행되므로 각각 적은 횟수)
  n_trials: 10  # 각 리샘플링 기법당 10회
  
  # 병렬 처리 설정
  n_jobs: 1  # 병렬 처리 시 1로 설정 (MLflow 충돌 방지)
  
  # 조기 종료 설정
  early_stopping:
    enabled: true
    patience: 10  # 10번 연속 개선 없으면 조기 종료
    min_trials: 5  # 최소 5번은 시도

# Optuna Sampler 설정
sampler:
  # 사용할 샘플러 타입
  type: "tpe"  # "tpe", "random", "cmaes", "nsgaii", "qmc"
  
  # TPE 설정 (type이 "tpe"일 때)
  tpe:
    n_startup_trials: 3  # 초기 랜덤 시도 횟수 (적은 수로 설정)
    n_ei_candidates: 24   # EI 계산 후보 수
    multivariate: true    # 다변량 TPE 사용
    group: true           # 그룹화된 파라미터 지원
  
  # CMA-ES 설정 (type이 "cmaes"일 때)
  cmaes:
    x0:  # 초기 중앙값 (기본 설정과 연동)
      n_estimators: 100
      max_depth: 6
      learning_rate: 0.1
      subsample: 0.8
      colsample_bytree: 0.8
      min_child_weight: 1
      reg_alpha: 0.1
      reg_lambda: 1.0
    sigma0: 0.1  # 초기 표준편차

# XGBoost 하이퍼파라미터 검색 범위 (리샘플링에 최적화)
xgboost_params:
  # 트리 개수 (리샘플링에서는 적당한 범위)
  n_estimators:
    type: "int"
    low: 50
    high: 300
    log: false
  
  # 최대 깊이
  max_depth:
    type: "int"
    low: 3
    high: 10
    log: false
  
  # 학습률
  learning_rate:
    type: "float"
    low: 0.01
    high: 0.3
    log: true
  
  # 서브샘플 비율
  subsample:
    type: "float"
    low: 0.6
    high: 1.0
    log: false
  
  # 컬럼 서브샘플 비율
  colsample_bytree:
    type: "float"
    low: 0.6
    high: 1.0
    log: false
  
  # 최소 자식 가중치
  min_child_weight:
    type: "int"
    low: 1
    high: 10
    log: false
  
  # L1 정규화
  reg_alpha:
    type: "float"
    low: 1e-8
    high: 10.0
    log: true
  
  # L2 정규화
  reg_lambda:
    type: "float"
    low: 1e-8
    high: 10.0
    log: true
  
  # 불균형 처리 (자동 계산되지만 튜닝 가능)
  scale_pos_weight:
    type: "float"
    low: 0.5
    high: 10.0
    log: true
  
  # Focal Loss 사용 여부 (categorical)
  use_focal_loss:
    type: "categorical"
    choices: [true, false]
  
  # Focal Loss Alpha 파라미터 (클래스 가중치)
  focal_loss_alpha:
    type: "float"
    low: 0.1
    high: 0.9
    log: false
  
  # Focal Loss Gamma 파라미터 (포커싱 파라미터)
  focal_loss_gamma:
    type: "float"
    low: 0.5
    high: 5.0
    log: false

# 평가 지표 설정 (불균형 데이터에 최적화)
evaluation:
  # 주요 최적화 지표 (F1-Score가 불균형 데이터에 적합)
  primary_metric: "f1_score"  # "f1_score", "precision", "recall", "roc_auc"
  
  # 다중 지표 최적화 (NSGA-II 사용 시)
  multi_objective:
    enabled: false
    metrics: ["f1_score", "recall", "precision"]
    directions: ["maximize", "maximize", "maximize"]
  
  # 교차 검증 설정 (기본 설정과 연동)
  cv:
    strategy: "group_kfold"  # 기본 설정의 validation.strategy 사용
    n_folds: 5              # 기본 설정의 validation.num_cv_folds 사용
    shuffle: false

# 결과 저장 설정
results:
  # 최고 모델 저장
  save_best_model: true
  model_save_path: "models/best_resampling_tuned_model.joblib"
  
  # 튜닝 결과 저장
  save_study: true
  study_save_path: "models/resampling_optuna_study.pkl"
  
  # 결과 시각화
  create_plots: true
  plots_save_path: "data/resampling_tuning_results/"

# MLflow 연동 설정
mlflow:
  # 실험 이름
  experiment_name: "resampling_hyperparameter_tuning"
  
  # 중첩 실행 사용
  use_nested_runs: true
  
  # 파라미터 로깅
  log_params: true
  
  # 메트릭 로깅
  log_metrics: true
  
  # 아티팩트 로깅
  log_artifacts: true

# 리샘플링 실험 설정
resampling_experiment:
  # 비교할 리샘플링 기법들
  methods:
    - "none"           # 리샘플링 없음 (베이스라인)
    - "smote"          # SMOTE
    - "borderline_smote"  # Borderline SMOTE
    - "adasyn"         # ADASYN
    - "under_sampling" # 언더샘플링
    - "hybrid"         # 하이브리드
  
  # 각 기법별 설정
  method_configs:
    smote:
      k_neighbors: 5
      random_state: 42
    
    borderline_smote:
      k_neighbors: 5
      random_state: 42
    
    adasyn:
      k_neighbors: 5
      random_state: 42
    
    under_sampling:
      strategy: "random"
      random_state: 42
    
    hybrid:
      strategy: "smote_tomek"
      random_state: 42
  
  # 비교 분석 설정
  comparison:
    # 통계적 검정
    statistical_test: "wilcoxon"  # "wilcoxon", "ttest", "mannwhitney"
    significance_level: 0.05
    
    # 효과 크기
    effect_size: "cohens_d"  # "cohens_d", "hedges_g"
    
    # 비교할 메트릭들
    metrics:
      - "f1_score"
      - "recall"
      - "precision"
      - "balanced_accuracy"
      - "roc_auc"

# 실험 설정
experiment:
  # 리샘플링 기법별 실험
  resampling_methods:
    - "smote"
    - "borderline_smote"
    - "adasyn"
    - "under_sampling"
    - "hybrid"
    - "none"  # 리샘플링 없음 (베이스라인)
  
  # 각 기법별 튜닝 횟수
  trials_per_method: 10
  
  # 비교 실험 설정
  comparison:
    enabled: true
    baseline_method: "none"
    metrics_to_compare:
      - "suicide_a_next_year_recall"
      - "suicide_a_next_year_f1"
      - "suicide_a_next_year_balanced_accuracy"
      - "suicide_a_next_year_pr_auc"
  
  # 결과 분석
  analysis:
    statistical_test: "wilcoxon"  # "wilcoxon", "ttest", "mannwhitney"
    significance_level: 0.05
    effect_size: "cohens_d"  # "cohens_d", "hedges_g"

# 모델 설정 (리샘플링에 최적화)
model:
  xgboost:
    # 조기 종료 (리샘플링 실험에서는 빠르게)
    early_stopping_rounds: 10
    verbose: 0  # 로그 최소화

# 학습 설정
training:
  # 조기 종료 (리샘플링 실험에서는 빠르게)
  patience: 5
  handle_imbalance: true 