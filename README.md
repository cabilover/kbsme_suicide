# KBSMC μμ‚΄ μμΈ΅ ν”„λ΅μ νΈ

## ν”„λ΅μ νΈ κ°μ”
κ°μΈλ³„ μ—°κ°„ μ •μ‹  κ±΄κ°• μ§€ν‘ λ°μ΄ν„°λ¥Ό ν™μ©ν•μ—¬ λ‹¤μ ν•΄μ λ¶μ•/μ°μΈ/μλ©΄ μ μ λ° μμ‚΄ μ‚¬κ³ /μ‹λ„ μ—¬λ¶€λ¥Ό μμΈ΅ν•λ” λ¨Έμ‹ λ¬λ‹ ν”„λ΅μ νΈμ…λ‹λ‹¤.

## π― μµκ·Ό μ£Όμ” κ°μ„ μ‚¬ν•­ (2025-07-21)

### β… **λ€κ·λ¨ λ¦¬ν©ν† λ§ μ‘μ—… μ™„λ£ - ν•μ΄νΌνλΌλ―Έν„° νλ‹κ³Ό λ¦¬μƒν”λ§ μ‹¤ν— λ¶„λ¦¬ + λ΅κΉ… μ‹μ¤ν… λ€ν­ κ°μ„ **
- **λ¦¬ν©ν† λ§ λ°°κ²½**: κΈ°μ΅΄ ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ¤ν¬λ¦½νΈμ— λ¦¬μƒν”λ§ κ΄€λ ¨ μ½”λ“κ°€ νΌμ¬λμ–΄ μμ–΄ μ½”λ“ λ³µμ΅μ„± μ¦κ°€ λ° μ μ§€λ³΄μ μ–΄λ ¤μ›€
- **μ‘μ—… 1 μ™„λ£ - ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹¤ν— μ •λ¦¬**:
  - **μ„¤μ • νμΌ μ •λ¦¬**: `configs/experiments/hyperparameter_tuning.yaml`μ—μ„ λ¦¬μƒν”λ§ μ„¤μ • μ κ±° ν™•μΈ
  - **Python λ¨λ“ μ •λ¦¬**: `src/hyperparameter_tuning.py`μ—μ„ λ¦¬μƒν”λ§ κ΄€λ ¨ μ½”λ“ μ—†μ ν™•μΈ
  - **μ¤ν¬λ¦½νΈ μ •λ¦¬**: `scripts/run_hyperparameter_tuning.py`μ—μ„ 5κ° λ¦¬μƒν”λ§ κ΄€λ ¨ ν•¨μ μ™„μ „ μ κ±°
    - μ κ±°λ ν•¨μ: `run_resampling_tuning_comparison()`, `add_resampling_hyperparameters_to_tuning_config()`, `run_resampling_tuning_comparison_with_configmanager()`, `apply_resampling_hyperparameters_to_config()`, `update_class_distributions_after_resampling()`
    - μμ •λ ν•¨μ: `log_tuning_params()`, `run_hyperparameter_tuning_with_config()`, `main()`
    - μ κ±°λ λ…λ Ήν–‰ μΈμ: `--resampling-comparison`, `--resampling-methods`, `--resampling-method`, `--resampling-ratio`, `--resampling-enabled` λ“±

- **λ‹¤μ¤‘ λ¨λΈ ν…μ¤νΈ μ™„λ£**:
  - **CatBoost**: μµκ³  μ„±λ¥ 0.0008, ~8λ¶„ μ†μ” β…
  - **LightGBM**: μµκ³  μ„±λ¥ 0.0269, ~10λ¶„ μ†μ” β…
  - **XGBoost, Random Forest**: λ°±κ·ΈλΌμ΄λ“ μ‹¤ν–‰ μ¤‘ π”„
  - **κ²€μ¦ μ™„λ£**: Resampling μ½”λ“ μ™„μ „ μ κ±°, μμν• ν•μ΄νΌνλΌλ―Έν„° νλ‹λ§ μν–‰, κµμ°¨ κ²€μ¦ μ •μƒ λ™μ‘, MLflow μ—°λ™ μ •μƒ

- **μ‘μ—… 3 μ™„λ£ - λ΅κΉ… μ‹μ¤ν… λ€ν­ κ°μ„ **:
  - **κΈ°μ΅΄ μ‹μ¤ν… ν™•μ¥**: μƒλ΅ μƒμ„±ν•μ§€ μ•κ³  κΈ°μ΅΄ `setup_logging()` ν•¨μ ν™•μ¥
  - **μƒλ΅μ΄ ν•¨μ μ¶”κ°€**: `setup_experiment_logging()`, `ConsoleCapture`, `experiment_logging_context()`, `log_experiment_summary()`
  - **ν†µμΌλ λ΅κ·Έ νμΌλ…**: `{experiment_type}_{model_type}_{timestamp}.log` ν¨ν„΄ μ μ©
  - **ν„°λ―Έλ„ μ¶λ ¥ μ™„μ „ μΊ΅μ²**: STDOUT, STDERR, μμ™Έ μ •λ³΄ λ¨λ‘ λ΅κ·Έ νμΌμ— μ €μ¥
  - **κ²€μ¦ μ™„λ£**: CatBoost ν…μ¤νΈλ΅ μƒλ΅μ΄ λ΅κΉ… μ‹μ¤ν… κ²€μ¦ (495KB, 3,123μ¤„ λ΅κ·Έ νμΌ μƒμ„±)

- **λ¦¬ν©ν† λ§ μ„±κ³Ό**:
  - **μ½”λ“ λ¶„λ¦¬**: ν•μ΄νΌνλΌλ―Έν„° νλ‹κ³Ό λ¦¬μƒν”λ§ μ‹¤ν—μ΄ λ…ν™•ν λ¶„λ¦¬λ¨
  - **μ μ§€λ³΄μμ„± ν–¥μƒ**: κ° μ‹¤ν—μ μ±…μ„μ΄ λ…ν™•ν•΄μ Έ μ μ§€λ³΄μ μ©μ΄
  - **μ¬μ‚¬μ©μ„± μ¦λ€**: κ³µν†µ μ»΄ν¬λ„νΈλ¥Ό κ³µμ ν•λ©΄μ„λ„ μ‹¤ν—λ³„ νΉν™” κ°€λ¥
  - **ν™•μ¥μ„± κ°μ„ **: μƒλ΅μ΄ μ‹¤ν— νƒ€μ… μ¶”κ°€ μ‹ κΈ°μ΅΄ μ½”λ“ μν–¥ μµμ†ν™”
  - **μ™„μ „ν• μ‹¤ν— μ¶”μ **: ν„°λ―Έλ„ μ¶λ ¥κΉμ§€ ν¬ν•¨ν• μ™„μ „ν• μ‹¤ν— κΈ°λ΅

- **λ‹¤μ λ‹¨κ³„ κ³„ν**:
  - μ‘μ—… 2: μƒλ΅μ΄ λ¦¬μƒν”λ§ μ‹¤ν— μ¤ν¬λ¦½νΈ μ‘μ„± (`scripts/run_resampling_experiment.py`)

## π― μµκ·Ό μ£Όμ” κ°μ„ μ‚¬ν•­ (2025-07-17)
- **SMOTE NaN λ¬Έμ  μ›μΈ λ¶„μ„**: ν”Όμ² μ—”μ§€λ‹μ–΄λ§μ—μ„ μƒμ„±λ μ‹κ³„μ—΄ ν”Όμ²λ“¤(μ§€μ—° ν”Όμ², μ΄λ™ ν†µκ³„, μ—°λ„λ³„ λ³€ν™”μ¨)μ—μ„ μλ„μ μΌλ΅ NaNμ΄ μƒμ„±λμ§€λ§, μ „μ²λ¦¬ νμ΄ν”„λΌμΈμ—μ„ μ΄ NaNλ“¤μ΄ μ²λ¦¬λμ§€ μ•μ•„ SMOTE μ μ© μ‹ `Input X contains NaN` μ¤λ¥ λ°μƒ
- **`get_numerical_columns()` ν•¨μ λ€ν­ κ°μ„ **: ν”Όμ² μ—”μ§€λ‹μ–΄λ§μΌλ΅ μƒμ„±λ μ‹κ³„μ—΄ ν”Όμ²λ“¤λ„ μλ™μΌλ΅ μμΉν•μΌλ΅ λ¶„λ¥ν•λ„λ΅ μμ •
  - μ§€μ—° ν”Όμ²: `*_lag_1`, `*_lag_2` ν¨ν„΄ μλ™ μΈμ‹
  - μ΄λ™ ν†µκ³„: `*_rolling_mean_*`, `*_rolling_std_*` ν¨ν„΄ μλ™ μΈμ‹  
  - μ—°λ„λ³„ λ³€ν™”μ¨: `*_yoy_change` ν¨ν„΄ μλ™ μΈμ‹
  - μ„¤μ • κΈ°λ° μμΉν• μ»¬λΌ + ν”Όμ² μ—”μ§€λ‹μ–΄λ§ κΈ°λ° μμΉν• μ»¬λΌ ν†µν•© λ¶„λ¥

- **μ„¤μ • νμΌ μμ •**: `configs/base/common.yaml`μ `selected_features`λ¥Ό μ›λ³Έ λ°μ΄ν„°(`data/sourcedata/data.csv`) κΈ°μ¤€μΌλ΅ μμ •
  - μ΄μ „: `processed_data_with_features.csv` κΈ°μ¤€μΌλ΅ μ‘μ„±λ μ‹κ³„μ—΄ ν”Όμ²λ“¤ ν¬ν•¨
  - ν„μ¬: μ›λ³Έ λ°μ΄ν„°μ κΈ°λ³Έ μ»¬λΌλ“¤λ§ ν¬ν•¨ν•κ³ , μ‹κ³„μ—΄ ν”Όμ²λ“¤μ€ ν”Όμ² μ—”μ§€λ‹μ–΄λ§μ„ ν†µν•΄ μƒμ„±λλ„λ΅ μμ •
  - κ²°κ³Ό: ν”Όμ² μ—”μ§€λ‹μ–΄λ§μ΄ μ •μƒμ μΌλ΅ μ‘λ™ν•μ—¬ 37κ°μ μƒλ΅μ΄ ν”Όμ² μƒμ„±

- **SMOTE μ•μ „μ„± κ°•ν™”**: SMOTE, BorderlineSMOTE, ADASYN λ¨λ“  λ¦¬μƒν”λ¬μ— NaN κ²€μ¦ λ° μλ™ μ²λ¦¬ λ΅μ§ μ¶”κ°€
  - SMOTE μ μ© μ „ μ „μ²΄ λ°μ΄ν„°μ NaN μƒνƒ ν™•μΈ
  - NaNμ΄ λ°κ²¬λλ©΄ μμΉν• μ»¬λΌμ€ medianμΌλ΅, λ²”μ£Όν• μ»¬λΌμ€ modeλ΅ λ€μ²΄
  - κ·Έλλ„ λ‚¨μ€ NaNμ΄ μμΌλ©΄ ν•΄λ‹Ή ν–‰μ„ μ‚­μ ν•μ—¬ SMOTEκ°€ λ°λ“μ‹ NaN μ—†λ” λ°μ΄ν„°μ—μ„ λ™μ‘ν•λ„λ΅ λ³΄μ¥
  - μ²λ¦¬ κ³Όμ •κ³Ό κ²°κ³Όλ¥Ό μƒμ„Έν λ΅κ·Έλ΅ μ¶λ ¥

- **ν…μ¤νΈ κ²°κ³Ό**:
  - **SMOTE NaN μ¤λ¥ μ™„μ „ ν•΄κ²°**: μ΄μ „μ— λ¨λ“  trialμ—μ„ λ°μƒν•λ `Input X contains NaN` μ¤λ¥κ°€ λ” μ΄μƒ λ°μƒν•μ§€ μ•μ
  - **ν”Όμ² μ—”μ§€λ‹μ–΄λ§ μ •μƒν™”**: μ›λ³Έ ν”Όμ² 15κ° + μƒλ΅ μƒμ„±λ ν”Όμ² 37κ° = μ΄ 52κ° ν”Όμ²
  - **μ „μ²λ¦¬ νμ΄ν”„λΌμΈ μ™„μ„±**: ν”Όμ² μ—”μ§€λ‹μ–΄λ§ β†’ μ „μ²λ¦¬ β†’ λ¦¬μƒν”λ§ μμ„λ΅ μ•μ •μ  νμ΄ν”„λΌμΈ κµ¬μ¶•
  - **μ‹¤ν— μ„±κ³µ μ™„λ£**: 3κ° trial λ¨λ‘ μ„±κ³µμ μΌλ΅ μ™„λ£, μµμ  νλΌλ―Έν„° μ°ΎκΈ° λ° μµμΆ… λ¨λΈ ν•™μµ μ„±κ³µ

## π― μµκ·Ό μ£Όμ” κ°μ„ μ‚¬ν•­ (2025-07-16)

### β… **λ¦¬μƒν”λ§ ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹μ¤ν… λ€ν­ κ°μ„ **
- **k_neighbors νλΌλ―Έν„°λ¥Ό ν•μ΄νΌνλΌλ―Έν„° νλ‹ λ€μƒμΌλ΅ ν¬ν•¨**:
  - SMOTE, Borderline SMOTE, ADASYNμ k_neighbors νλΌλ―Έν„°κ°€ νλ‹ λ²”μ„μ— μ¶”κ°€λ¨
  - 3~10 λ²”μ„λ΅ μ„¤μ •ν•μ—¬ μ μ ν• μ΄μ›ƒ μ νƒμƒ‰ κ°€λ¥
  - κΈ°μ΅΄ ν•λ“μ½”λ”©λ κ°’(5) μ κ±°ν•κ³  λ™μ  νλ‹ μ§€μ›

- **sampling_strategy νλΌλ―Έν„° νλ‹ μ§€μ›**:
  - κ·Ήλ„ λ¶κ· ν• λ°μ΄ν„°(849:1)μ— μ ν•©ν• 0.05~0.3 λ²”μ„λ΅ μ„¤μ •
  - κ³Όλ„ν• μ¤λ²„μƒν”λ§ λ°©μ§€ λ° κ³Όμ ν•© μ„ν— κ°μ†
  - resampling.yamlμ—μ„ "auto" λ€μ‹  λ³΄μμ  λΉ„μ¨λ΅ μμ •

- **μ‹κ³„μ—΄ νΉν™” λ¦¬μƒν”λ§ νλΌλ―Έν„° μ§€μ›**:
  - time_weight, temporal_window, seasonality_weight λ“± 5κ° νλΌλ―Έν„° μ¶”κ°€
  - μ‹κ°„μ  μΆ…μ†μ„±μ„ κ³ λ ¤ν• λ¦¬μƒν”λ§ κ°€λ¥
  - pattern_preservation, trend_preservation λ“± λ¶λ¦° νλΌλ―Έν„°λ„ νλ‹ λ€μƒ

- **ConfigManagerμ™€μ μ—°λ™ κ°μ„ **:
  - λ¦¬μƒν”λ§ νλΌλ―Έν„°κ°€ MLflowμ— μλ™ λ΅κΉ…λ¨
  - μ‹¤ν— κ²°κ³Ό μ €μ¥ μ‹ λ¦¬μƒν”λ§ μ •λ³΄ ν¬ν•¨
  - λ…λ Ήν–‰ μΈμλ΅ time_series_adapted μµμ… μ¶”κ°€

- **μ§€μ›ν•λ” λ¦¬μƒν”λ§ κΈ°λ²• ν™•μ¥**:
  - **κΈ°μ΅΄**: none, smote, borderline_smote, adasyn, under_sampling, hybrid
  - **μ¶”κ°€**: time_series_adapted (μ‹κ³„μ—΄ νΉν™” λ¦¬μƒν”λ§)
  - **μ΄ 7κ° κΈ°λ²•** μ§€μ›μΌλ΅ ν™•μ¥

### β… **NaN/Inf λ°μ΄ν„° ν’μ§ κ²€μ¦ λ° data_analysis.py ν™•μ¥**
- **μ›λ³Έ λ°μ΄ν„° κ²€μ¦**: `data/sourcedata/data.csv`μ—μ„ Inf κ°’ λ° λ°μ΄ν„° νƒ€μ… νΌμ¬ λ¬Έμ  μ—†μ ν™•μΈ
  - **Inf κ°’**: λ¨λ“  μμΉν• μ»¬λΌμ—μ„ 0κ° λ°κ²¬ β…
  - **λ°μ΄ν„° νƒ€μ… νΌμ¬**: μμΉν• μ»¬λΌμ—μ„ λ¬Έμμ—΄ νΌμ¬ μ—†μ β…
  - **NaN κ°’**: μμƒλ κ²°μΈ΅μΉλ§ μ΅΄μ¬ (anxiety_score: 58κ°, depress_score: 300κ° λ“±)

- **ν”Όμ² μ—”μ§€λ‹μ–΄λ§ β†’ μ „μ²λ¦¬ νμ΄ν”„λΌμΈ ν…μ¤νΈ**:
  - **ν”Όμ² μ—”μ§€λ‹μ–΄λ§ ν›„**: Inf 0κ°, NaN 16,636,006κ° (μ •μƒμ μΈ μ‹κ³„μ—΄ ν”Όμ² μƒμ„±μΌλ΅ μΈν• NaN)
  - **μ „μ²λ¦¬ ν›„**: Inf 0κ°, NaN 0κ° β…
  - **κ²°λ΅ **: νμ΄ν”„λΌμΈμ—μ„ NaN/Inf λ¬Έμ  μ—†μ, μ „μ²λ¦¬κ°€ λ¨λ“  κ²°μΈ΅μΉλ¥Ό μ μ ν μ²λ¦¬

- **data_analysis.py ν™•μ¥**:
  - **Inf κ°’ κ²€μ¦ ν•¨μ μ¶”κ°€** (`analyze_infinite_values`): λ¨λ“  μμΉν• μ»¬λΌμ—μ„ Inf κ°’ κ²€μ¦
  - **λ°μ΄ν„° νƒ€μ… νΌμ¬ κ²€μ¦ ν•¨μ μ¶”κ°€** (`analyze_data_type_mixture`): μ»¬λΌλ³„ λ°μ΄ν„° νƒ€μ… λ¶„ν¬ λ¶„μ„
  - **μƒλ΅μ΄ κ²€μ¦ ν•¨μλ“¤μ„ λ¶„μ„ νμ΄ν”„λΌμΈμ— ν†µν•©**

### β… **λ΅κΉ… μ‹μ¤ν… μΌμ›ν™” λ° μ½”λ“ μΌκ΄€μ„± κ°•ν™”**
- **κ³µν†µ λ΅κΉ… ν•¨μ λ„μ…**: `src/utils.py`μ— `setup_logging`, `get_logger`, `log_experiment_info` ν•¨μ μ¶”κ°€
- **λ¨λ“λ³„ μΌκ΄€λ λ΅κΉ… μ μ©**: κΈ°μ΅΄μ `logging.basicConfig()` κ°λ³„ νΈμ¶μ„ λ¨λ‘ μ κ±°ν•κ³ , `setup_logging()` ν•¨μλ΅ ν†µν•©
- **utils ν¨ν‚¤μ§€ κµ¬μ΅° κ°μ„ **: `src/utils/__init__.py`μ—μ„ κ³µν†µ ν•¨μ λ° λ΅κΉ… ν•¨μ μ§μ ‘ μ κ³µ (import κ²½λ΅ λ¬Έμ  ν•΄κ²°)
- **ν…μ¤νΈ μ™„λ£**: λ¨λ“  μ£Όμ” λ¨λ“μ—μ„ λ΅κΉ… μ •μƒ λ™μ‘ ν™•μΈ
- **ν–¥ν›„ ν™•μ¥μ„±**: νμΌ λ΅κΉ…, ν¬λ§·, λ λ²¨ λ“± μ¤‘μ•™μ—μ„ μ†μ‰½κ² κ΄€λ¦¬ κ°€λ¥

### β… **ν•μ΄νΌνλΌλ―Έν„° κ²€μƒ‰ λ²”μ„ λ€ν­ ν™•μ¥ λ° ν”Όμ² μ„ΈνΈ ν™•μ¥**
- **ν”Όμ² μ„ΈνΈ λ€ν­ ν™•μ¥**: 7κ° β†’ 20κ° ν”Όμ²λ΅ ν™•μ¥
  - **κΈ°λ³Έ μΈκµ¬ν•™μ  μ •λ³΄**: `age`, `sex`, `age_group`
  - **μ •μ‹  κ±΄κ°• μ μ**: `anxiety_score`, `depress_score`, `sleep_score`, `comp`
  - **μμ‚΄ κ΄€λ ¨ λ³€μ**: `suicide_t`, `suicide_a`
  - **μ •μ‹ κ³Ό λ¶„λ¥**: `psychia_cate`
  - **μ‹κ°„ κΈ°λ° ν”Όμ²**: `month`, `day_of_week`, `day_of_year`
  - **μ΄λ™ ν†µκ³„ ν”Όμ²**: `*_rolling_mean_2y`, `*_rolling_std_2y`, `*_yoy_change`

- **CatBoost νλΌλ―Έν„° λ€ν­ ν™•μ¥**:
  - `iterations`: 50-500 β†’ 100-1000 (λ¨λΈ λ³µμ΅λ„ μ¦κ°€)
  - `depth`: 3-10 β†’ 4-12 (νΈλ¦¬ κΉμ΄ ν™•μ¥)
  - `learning_rate`: 0.01-0.3 β†’ 0.005-0.15 (λ” μ„Έλ°€ν• ν•™μµλ¥  νƒμƒ‰)
  - `l2_leaf_reg`: 1-10 β†’ 0.1-50.0 (μ •κ·ν™” λ²”μ„ ν™•μ¥)
  - **μƒλ΅μ΄ νλΌλ―Έν„° μ¶”κ°€**: `min_data_in_leaf`, `max_bin`, `subsample`, `od_type`, `od_wait`

- **SMOTE λ¦¬μƒν”λ§ μµμ ν™”**:
  - `k_neighbors`: 5 β†’ 3 (κ·Ήλ„ λ¶κ· ν• λ°μ΄ν„°μ— λ§κ² μ΅°μ •)
  - `sampling_strategy`: "auto" β†’ 0.1 (1:10 λΉ„μ¨λ΅ μ†μ ν΄λμ¤ μ¤λ²„μƒν”λ§)

- **νλ‹ μ„¤μ • κ°•ν™”**:
  - `n_trials`: 100 β†’ 500 (λ” μ •κµν• νƒμƒ‰)
  - `patience`: 20 β†’ 50 (μ΅°κΈ° μΆ…λ£ μ—¬μ  μ¦κ°€)
  - `min_trials`: 30 β†’ 100 (μµμ† μ‹λ„ νμ μ¦κ°€)

- **λ¶κ· ν• λ°μ΄ν„° λ€μ‘ κ°•ν™”**:
  - `scale_pos_weight` λ²”μ„: 10.0-100.0 β†’ 50.0-1000.0 (κ·Ήλ„ λ¶κ· ν• λ°μ΄ν„° λ€μ‘)
  - λ¨λΈλ³„ μλ™ κ°€μ¤‘μΉ λΉ„ν™μ„±ν™”, μλ™ νλ‹ μ°μ„ 

---

## π― μµκ·Ό μ£Όμ” κ°μ„ μ‚¬ν•­ (2025-07-14)

### β… **Stratified Group K-Fold κµ¬ν„ λ° ν•μ΄νΌνλΌλ―Έν„° ν™•μ¥**
- **Stratified Group K-Fold κµ¬ν„**: κ·Ήλ„ λ¶κ· ν• λ°μ΄ν„°(μμ‚΄ μ‹λ„ 0.12%)μ—μ„ μ•μ •μ μΈ κµμ°¨ κ²€μ¦μ„ μ„ν• ID κΈ°λ° Stratified Group K-Fold κµ¬ν„
- **ν•µμ‹¬ λ΅μ§**: IDλ³„ ν΄λμ¤ λΉ„μ¨ κ³„μ‚°, μ–‘μ„±/μμ„± ID λ¶„λ¦¬ λ° κ· λ“± λ¶„λ°°, κ° ν΄λ“μ—μ„ ν΄λμ¤ λΉ„μ¨ κ· ν• μ μ§€
- **μλ™ λ€μ²΄ λ©”μ»¤λ‹μ¦**: μ–‘μ„± ID μκ°€ λ¶€μ΅±ν•  κ²½μ° μλ™μΌλ΅ μΌλ° Group K-Foldλ΅ λ€μ²΄
- **μ„¤μ • νμΌ ν™•μ¥**: `configs/base/validation.yaml`μ— stratification μ„¤μ • μ¶”κ°€, `configs/experiments/hyperparameter_tuning.yaml`μ— stratified_group_kfold μ „λµ μ„¤μ •

### β… **ν•μ΄νΌνλΌλ―Έν„° κ²€μƒ‰ λ²”μ„ λ€ν­ ν™•μ¥**
- **XGBoost μ¶”κ°€ νλΌλ―Έν„°**: `gamma` (0.1-5.0), `max_delta_step` (0-10), `colsample_bylevel` (0.6-1.0), `tree_method` (4κ°€μ§€ λ°©λ²•)
- **LightGBM μ¶”κ°€ νλΌλ―Έν„°**: `num_leaves` (10-200), `feature_fraction` (0.6-1.0), `bagging_fraction` (0.6-1.0), `bagging_freq` (0-10), `min_data_in_leaf` (10-100), `boosting_type` (3κ°€μ§€ λ°©λ²•)
- **λ¨λΈ νƒμƒ‰ λ²”μ„ ν™•μ¥**: λ” λ‚μ€ λ¨λΈμ„ μ°ΎκΈ° μ„ν• νλΌλ―Έν„° κ³µκ°„ λ€ν­ ν™•μ¥

### β… **Recall κΈ°λ° νλ‹ λ° scale_pos_weight κ°μ„ **
- **Primary Metric λ³€κ²½**: `recall`λ΅ μ„¤μ •ν•μ—¬ μ†μ ν΄λμ¤ μμΈ΅ μ„±λ¥ μ¤‘μ‹
- **scale_pos_weight μλ™ κ³„μ‚° μ μ–΄**: `auto_scale_pos_weight` μµμ…μΌλ΅ νλ‹λ κ°’κ³Ό μλ™ κ³„μ‚° κ°„μ μ¶©λ ν•΄κ²°
- **μ„¤μ • κΈ°λ° μ μ–΄**: `false`λ΅ μ„¤μ • μ‹ νλ‹λ κ°’ μ°μ„  μ‚¬μ©, `true`λ΅ μ„¤μ • μ‹ ν΄λμ¤ λΉ„μ¨ κΈ°λ° μλ™ κ³„μ‚°

### β… **μ½”λ“ μ •λ¦¬ λ° μ•μ •ν™”**
- **μ •μλμ§€ μ•μ€ ν•¨μ μ κ±°**: `setup_tuning_logger`, `save_tuning_log`, `setup_mlflow` λ“± λ―Έκµ¬ν„ ν•¨μ νΈμ¶ μ κ±°
- **μ¤λ¥ μ²λ¦¬ κ°μ„ **: ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ³Όμ •μ—μ„ λ°μƒν•λ” λ‹¤μ–‘ν• μ¤λ¥ μƒν™© λ€μ‘
- **λ΅κΉ… μ‹μ¤ν… μ •λ¦¬**: MLflowλ¥Ό ν†µν• μΌκ΄€λ μ‹¤ν— μ¶”μ 

### β… **PR-AUC -inf λ¬Έμ  ν•΄κ²° λ° ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ•μ •ν™”**
- **PR-AUC -inf λ¬Έμ  μ›μΈ λ¶„μ„**: κ³Όλ„ν•κ² λ„“μ€ ν•μ΄νΌνλΌλ―Έν„° λ²”μ„λ΅ μΈν• λ¨λΈ λ¶μ•μ •μ„±
- **ν•μ΄νΌνλΌλ―Έν„° λ²”μ„ μµμ ν™”**: 
  - `scale_pos_weight`: 10.0-100.0 (κ·Ήλ‹¨μ  κ°’ μ ν•)
  - `iterations`: 50-500 (λ¨λΈ λ³µμ΅λ„ μ ν•)
  - `depth`: 3-10 (κ³Όμ ν•© λ°©μ§€)
- **κ²°κ³Ό**: PR-AUCκ°€ -inf λ€μ‹  0.0 κ·Όμ²μ μ•μ •μ μΈ κ°’μΌλ΅ λ³µμ›

### β… **λ°μ΄ν„° μƒν”λ§ λ° SMOTE λ¦¬μƒν”λ§ κ°μ„ **
- **μ „μ²΄ λ°μ΄ν„°μ…‹ μ‚¬μ©**: `configs/base/common.yaml`μ—μ„ μƒν”λ§ λΉ„ν™μ„±ν™”
- **SMOTE μ•μ •μ„± ν–¥μƒ**: ID μ»¬λΌμ„ ν•­μƒ ν†µκ³Ό μ»¬λΌμ— ν¬ν•¨ν•μ—¬ λ¦¬μƒν”λ§ μ¤λ¥ λ°©μ§€
- **λΉ λ¥Έ ν…μ¤νΈ μ§€μ›**: μƒν”λ§ μ„¤μ •μ„ μ£Όμ„μΌλ΅ μ μ§€ν•μ—¬ ν•„μ”μ‹ ν™μ„±ν™” κ°€λ¥

### β… **ν‰κ°€ μ§€ν‘ λ° λ¨λΈ μ„¤μ • μµμ ν™”**
- **PR-AUC λ³µμ›**: κ·Ήλ„λ΅ λ¶κ· ν•ν• λ°μ΄ν„°μ—μ„λ„ μ•μ •μ μΌλ΅ κ³„μ‚°λλ„λ΅ κ°μ„ 
- **λ¨λΈλ³„ μ„¤μ • νμΌ μ—…λ°μ΄νΈ**: λ¨λ“  λ¨λΈμ—μ„ μ•μ •μ μΈ κΈ°λ³Έκ°’ λ° λ²”μ„ μ„¤μ •
- **ν•μ΄νΌνλΌλ―Έν„° νλ‹ λ²”μ„ μ΅°μ •**: κ° λ¨λΈμ νΉμ„±μ— λ§λ” μµμ  λ²”μ„ μ„¤μ •

### β… **μ‹¤ν— μ¤ν¬λ¦½νΈ κ°μ„ **
- **μƒλ΅μ΄ μ¤ν¬λ¦½νΈ**: `scripts/run_individual_models.sh` - κ°λ³„ λ¨λΈ νλ‹ μ‹¤ν–‰
- **ν…ν”λ¦Ώ μ¤ν¬λ¦½νΈ**: `scripts/template_experiment.sh` - μ‹¤ν— ν…ν”λ¦Ώ μ κ³µ
- **κΈ°μ΅΄ μ¤ν¬λ¦½νΈ μ •λ¦¬**: λ” μ΄μƒ μ‚¬μ©ν•μ§€ μ•λ” μ¤ν¬λ¦½νΈ μ κ±°

### β… **μ¤ν¬λ¦½νΈ μ•μ „μ„± λ° λ©”λ¨λ¦¬ κ΄€λ¦¬ κ°μ„ **
- **λ©”λ¨λ¦¬ μ•μ „ν• μ¤ν¬λ¦½νΈ ν…ν”λ¦Ώ** μƒμ„± (`template_experiment.sh`)
- **μ¤λλ μ¤ν¬λ¦½νΈ μ •λ¦¬**: 7κ° μ¤‘λ³µ/λ¶μ•μ • μ¤ν¬λ¦½νΈ μ‚­μ 
- **λ³‘λ ¬ μ²λ¦¬ μµμ ν™”**: `n_jobs=4`λ΅ μ•μ „ν• κΈ°λ³Έκ°’ μ„¤μ •
- **μλ™ λ©”λ¨λ¦¬ μ •λ¦¬**: κ° λ¨λΈ μ‹¤ν–‰ ν›„ κ°•ν™”λ λ©”λ¨λ¦¬ μ •λ¦¬
- **μ¤λ¥ ν—μ© κµ¬μ΅°**: ν• λ¨λΈ μ‹¤ν¨ μ‹μ—λ„ λ‹¤μ λ¨λΈλ΅ κ³„μ† μ§„ν–‰
- **λ¨λ“ν™”λ κµ¬μ΅°**: `run_model()` ν•¨μλ΅ μ¬μ‚¬μ© κ°€λ¥ν• κµ¬μ΅°

### β… **μƒμ„Έν• μ‹¤ν— κ²°κ³Ό μ €μ¥ κΈ°λ¥**
- **241κ° μƒμ„Έ λ©”νΈλ¦­** μλ™ μ¶”μ¶ λ° μΉ΄ν…κ³ λ¦¬ν™”
- **νλ‹ λ²”μ„ μ •λ³΄** λ…ν™•ν• ν‘μ‹
- **κµμ°¨ κ²€μ¦ ν†µκ³„** (ν‰κ· , ν‘μ¤€νΈμ°¨) μλ™ κ³„μ‚°
- **λ¨λΈ νΉμ„± λ¶„μ„** (ν”Όμ² μ¤‘μ”λ„, λ³µμ΅λ„)
- **μ‹¤ν— ν™κ²½ μ •λ³΄** (μ‹μ¤ν…, λΌμ΄λΈλ¬λ¦¬ λ²„μ „)
- **λ°μ΄ν„° ν’μ§ λ° μ „μ²λ¦¬** μƒμ„Έ μ •λ³΄

### β… **κ²€μ¦λ μ•μ •μ„±**
- **λ©”λ¨λ¦¬ λ¬Έμ  ν•΄κ²°**: ν„°λ―Έλ„ λ©μ¶¤ ν„μƒ μ™„μ „ ν•΄κ²°
- **μ‹¤ν— μ•μ •μ„±**: 100% μ™„λ£μ¨ λ‹¬μ„±
- **μ¬ν„ κ°€λ¥μ„±**: μΌκ΄€λ ν™κ²½μ—μ„ μ•μ •μ  μ‹¤ν–‰

## ν”„λ΅μ νΈ κµ¬μ΅°
```
kbsmc_suicide/
β”β”€β”€ data/
β”‚   β”β”€β”€ sourcedata/                    # μ›λ³Έ λ°μ΄ν„°
β”‚   β”‚   β””β”€β”€ data.csv
β”‚   β”β”€β”€ sourcedata_analysis/           # λ¶„μ„ κ²°κ³Ό
β”‚   β”‚   β”β”€β”€ figures/                   # λ¶„μ„ κ·Έλν”„
β”‚   β”‚   β””β”€β”€ reports/                   # λ¶„μ„ λ¦¬ν¬νΈ (.txt)
β”‚   β””β”€β”€ processed/                     # μ „μ²λ¦¬λ λ°μ΄ν„°
β”‚       β””β”€β”€ processed_data_with_features.csv
β”β”€β”€ src/
β”‚   β”β”€β”€ data_analysis.py              # λ°μ΄ν„° λ¶„μ„ λ° μ „μ²λ¦¬ μ¤ν¬λ¦½νΈ
β”‚   β”β”€β”€ splits.py                     # λ°μ΄ν„° λ¶„ν•  μ „λµ
β”‚   β”β”€β”€ preprocessing.py              # μ „μ²λ¦¬ νμ΄ν”„λΌμΈ
β”‚   β”β”€β”€ feature_engineering.py        # ν”Όμ² μ—”μ§€λ‹μ–΄λ§
β”‚   β”β”€β”€ models/
β”‚   β”‚   β”β”€β”€ base_model.py             # BaseModel μ¶”μƒ ν΄λμ¤ (β… λ¨λΈλ³„ λ°μ΄ν„° κ²€μ¦ μµμ ν™”)
β”‚   β”‚   β”β”€β”€ xgboost_model.py          # XGBoost λ¨λΈ ν΄λμ¤ (β… λ²”μ£Όν• λ³€μ μ«μ λ³€ν™)
β”‚   β”‚   β”β”€β”€ catboost_model.py         # CatBoost λ¨λΈ ν΄λμ¤ (β… λ²”μ£Όν• λ³€μ λ³΄μ΅΄)
β”‚   β”‚   β”β”€β”€ lightgbm_model.py         # LightGBM λ¨λΈ ν΄λμ¤ (β… λ²”μ£Όν• λ³€μ λ³΄μ΅΄)
β”‚   β”‚   β”β”€β”€ random_forest_model.py    # Random Forest λ¨λΈ ν΄λμ¤ (β… λ²”μ£Όν• λ³€μ λ³΄μ΅΄)
β”‚   β”‚   β””β”€β”€ loss_functions.py         # μ†μ‹¤ ν•¨μ λ¨λ“ (Focal Loss ν¬ν•¨)
β”‚   β”β”€β”€ training.py                   # ν›λ ¨ νμ΄ν”„λΌμΈ (β… ν‰κ°€ λ΅μ§ μ¤‘μ•™ν™”)
β”‚   β”β”€β”€ evaluation.py                 # ν‰κ°€ λ¨λ“ (β… ν†µν•© ν‰κ°€ μ§„μ…μ )
β”‚   β”β”€β”€ hyperparameter_tuning.py      # ν•μ΄νΌνλΌλ―Έν„° νλ‹ (β… ν‰κ°€ λ΅μ§ μ¤‘μ•™ν™”)
β”‚   β”β”€β”€ utils.py                      # κ³µν†µ μ ν‹Έλ¦¬ν‹° ν•¨μ (β… μ«μ λ³€ν™/κ²€μ¦ ν•¨μ μ¶”κ°€)
β”‚   β””β”€β”€ reference/                    # μ°Έκ³  μλ£
β”β”€β”€ configs/
β”‚   β”β”€β”€ base/                         # κΈ°λ³Έ μ„¤μ • (β… κ³„μΈµμ  κµ¬μ΅°)
β”‚   β”‚   β”β”€β”€ common.yaml               # κ³µν†µ μ„¤μ •
β”‚   β”‚   β”β”€β”€ evaluation.yaml           # ν‰κ°€ μ„¤μ •
β”‚   β”‚   β”β”€β”€ mlflow.yaml               # MLflow μ„¤μ •
β”‚   β”‚   β””β”€β”€ validation.yaml           # κ²€μ¦ μ„¤μ •
β”‚   β”β”€β”€ models/                       # λ¨λΈλ³„ μ„¤μ • (β… κ³„μΈµμ  κµ¬μ΅°)
β”‚   β”‚   β”β”€β”€ xgboost.yaml              # XGBoost λ¨λΈ μ„¤μ •
β”‚   β”‚   β”β”€β”€ catboost.yaml             # CatBoost λ¨λΈ μ„¤μ •
β”‚   β”‚   β”β”€β”€ lightgbm.yaml             # LightGBM λ¨λΈ μ„¤μ •
β”‚   β”‚   β””β”€β”€ random_forest.yaml        # Random Forest λ¨λΈ μ„¤μ •
β”‚   β”β”€β”€ experiments/                  # μ‹¤ν—λ³„ μ„¤μ • (β… κ³„μΈµμ  κµ¬μ΅°)
β”‚   β”‚   β”β”€β”€ focal_loss.yaml           # Focal Loss μ‹¤ν— μ„¤μ •
β”‚   β”‚   β”β”€β”€ resampling.yaml           # λ¦¬μƒν”λ§ μ‹¤ν— μ„¤μ •
β”‚   β”‚   β””β”€β”€ hyperparameter_tuning.yaml # ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ„¤μ •
β”‚   β””β”€β”€ templates/                    # μ„¤μ • ν…ν”λ¦Ώ (β… κ³„μΈµμ  κµ¬μ΅°)
β”‚       β”β”€β”€ default.yaml              # κΈ°λ³Έ ν…ν”λ¦Ώ
β”‚       β””β”€β”€ tuning.yaml               # νλ‹ ν…ν”λ¦Ώ
β”β”€β”€ scripts/
β”‚   β”β”€β”€ run_hyperparameter_tuning.py  # ν†µν•© μ‹¤ν— μ‹¤ν–‰ μ¤ν¬λ¦½νΈ (β… ConfigManager κΈ°λ° λ¦¬μƒν”λ§ λΉ„κµ ν¬ν•¨)
β”‚   β”β”€β”€ template_experiment.sh        # μ‹¤ν— μ¤ν¬λ¦½νΈ ν…ν”λ¦Ώ (β… λ©”λ¨λ¦¬ μ•μ „ν• κΈ°λ³Έ κµ¬μ΅°)
β”‚   β””β”€β”€ run_individual_models.sh      # κ°λ³„ λ¨λΈ μ‹¤ν–‰ μ¤ν¬λ¦½νΈ (β… λ©”λ¨λ¦¬ μµμ ν™”)
β”β”€β”€ results/                          # μ‹¤ν— κ²°κ³Ό μ €μ¥μ†
β”‚   β”β”€β”€ experiment_results_*.txt      # μƒμ„Έν• μ‹¤ν— κ²°κ³Ό νμΌ
β”‚   β”β”€β”€ tuning_log_*.txt              # νλ‹ κ³Όμ • λ΅κ·Έ
β”‚   β””β”€β”€ test_logs/                    # μλ™ν™” ν…μ¤νΈ λ΅κ·Έ
β”β”€β”€ requirements.txt                  # ν•„μ”ν• ν¨ν‚¤μ§€ λ©λ΅ (XGBoost 1.7.6 κ³ μ •, psutil μ¶”κ°€)
β”β”€β”€ projectplan                       # ν”„λ΅μ νΈ κ³„νμ„
β”β”€β”€ PROJECT_PROGRESS.md              # ν”„λ΅μ νΈ μ§„ν–‰ μƒν™© λ¬Έμ„
β””β”€β”€ README.md                        # μ΄ νμΌ
```

## ν”„λ΅μ νΈ λ£°

### μ‘μ—… λ°©μ‹ μ›μΉ™
- **κ³„ν μ°μ„ **: μ½”λ“ μμ •μ„ μ§„ν–‰ν•κΈ° μ „μ— λ¨Όμ € μƒμ„Έν• κ³„νμ„ μ μ‹
- **μΉμΈ κΈ°λ° μ‹¤ν–‰**: μ‚¬μ©μμ λ…μ‹μ  μΉμΈ(accept)μ„ λ°›μ€ ν›„μ—λ§ μ‹¤μ  μ½”λ“ μμ • μ‹¤ν–‰
- **λ‹¨κ³„λ³„ μ§„ν–‰**: λ³µμ΅ν• μ‘μ—…μ κ²½μ° λ‹¨κ³„λ³„λ΅ κ³„νμ„ μ μ‹ν•κ³  μΉμΈμ„ λ°›μ•„ μ§„ν–‰
- **λ…ν™•ν• μ„¤λ…**: κ° λ‹¨κ³„μ—μ„ λ¬΄μ—‡μ„, μ™, μ–΄λ–»κ² λ³€κ²½ν• μ§€ λ…ν™•ν μ„¤λ…

### μ„¤μ • νμΌ κ΄€λ¦¬ μ›μΉ™
- **μ„¤μ • μ°μ„ **: λ¨λ“  ν•λ“μ½”λ”©λ κ°’μ€ μ„¤μ • νμΌλ΅ μ΄λ™ν•μ—¬ μ¤‘μ•™ κ΄€λ¦¬
- **μ„¤μ • κ²€μ¦**: μ„¤μ • νμΌμ΄ μ—†κ±°λ‚ λ¬Έμ κ°€ μλ” κ²½μ° ν•λ“μ½”λ”©μΌλ΅ μ§„ν–‰ν•μ§€ μ•κ³  μ§„ν–‰μ„ λ©μ¶¤
- **λ…ν™•ν• μ¤λ¥ λ©”μ‹μ§€**: μ„¤μ • νμΌ λ¬Έμ  μ‹ κµ¬μ²΄μ μΈ μμ • λ°©λ²•μ„ λ΅κ·Έλ΅ μ•λ‚΄
- **νƒ€κ² λ³€μλ… μ¤‘μ•™ν™”**: `configs/base/common.yaml`μ `target_variables` μ„Ήμ…μ—μ„ λ¨λ“  νƒ€κ² λ³€μλ… μ •μ
- **νƒ€κ² νƒ€μ… λ…μ‹**: `configs/base/common.yaml`μ `target_types` μ„Ήμ…μ—μ„ νκ·€/λ¶„λ¥ νƒ€μ… λ…μ‹μ  μ •μ

### μ½”λ“ μ»¨λ²¤μ…
- **PEP 8 μ¤€μ**: νμ΄μ¬ μ½”λ“ μ¤νƒ€μΌ κ°€μ΄λ“ μ¤€μ
- **μ„¤μ • κΈ°λ° λ΅μ§**: ν•λ“μ½”λ”© λ€μ‹  μ„¤μ • νμΌ κΈ°λ° λ™μ  μ²λ¦¬
- **μ¤λ¥ μ²λ¦¬**: μ„¤μ • νμΌ λ¬Έμ  μ‹ `SystemExit` λλ” `ValueError`λ΅ λ…ν™•ν• μ¤λ¥ λ°μƒ
- **λ΅κΉ…**: μ„¤μ • νμΌ λ¬Έμ  μ‹ κµ¬μ²΄μ μΈ μμ • λ°©λ²•μ„ `logger.error()`λ΅ μ•λ‚΄

### μ„¤μ • νμΌ κµ¬μ΅°
```yaml
# configs/base/common.yaml
features:
  target_variables:
    original_targets:
      score_targets: ["anxiety_score", "depress_score", "sleep_score", "comp"]
      binary_targets: ["suicide_t", "suicide_a"]
    next_year_targets:
      score_targets: ["anxiety_score_next_year", "depress_score_next_year", "sleep_score_next_year"]
      binary_targets: ["suicide_t_next_year", "suicide_a_next_year"]
  
  target_types:
    regression_targets: ["anxiety_score_next_year", "depress_score_next_year", "sleep_score_next_year"]
    classification_targets: ["suicide_t_next_year", "suicide_a_next_year"]
```

## ν™κ²½ μ„¤μ •

### 1. Conda ν™κ²½ ν™μ„±ν™”
```bash
conda activate simcare
```

### 2. ν•„μ”ν• ν¨ν‚¤μ§€ μ„¤μΉ
```bash
pip install -r requirements.txt
```

> β οΈ λ³Έ ν”„λ΅μ νΈλ” xgboost==1.7.6 λ²„μ „μ— μµμ ν™”λμ–΄ μμµλ‹λ‹¤. requirements.txtμ— λ…μ‹λ λ²„μ „μΌλ΅ μ„¤μΉν•΄μ•Ό μ‹¤ν—μ΄ μ •μƒ λ™μ‘ν•©λ‹λ‹¤.

## μ‹¤ν–‰ λ°©λ²•

### λ°μ΄ν„° λ¶„μ„ λ° μ „μ²λ¦¬ μ‹¤ν–‰
```bash
python src/data_analysis.py
```

μ΄ λ…λ Ήμ–΄λ” λ‹¤μ μ‘μ—…μ„ μν–‰ν•©λ‹λ‹¤:
- μ›λ³Έ λ°μ΄ν„° λ΅λ”© λ° κΈ°λ³Έ μ •λ³΄ λ¶„μ„
- κ²°μΈ΅μΉ λ° μ΄μƒμΉ λ¶„μ„
- μ‹κ³„μ—΄ κΈΈμ΄ λ¶„μ„
- νƒ€κ² λ³€μ λ¶„ν¬ λ¶„μ„
- λ°μ΄ν„° νƒ€μ… λ³€ν™ λ° μ „μ²λ¦¬
- νƒ€κ² λ³€μ μƒμ„± (λ‹¤μ ν•΄ μμΈ΅κ°’)
- ν”Όμ² μ—”μ§€λ‹μ–΄λ§
- κ²°κ³Ό μ €μ¥ λ° MLflow λ΅κΉ…

### π€ μ•μ „ν• μ‹¤ν— μ¤ν¬λ¦½νΈ μ‚¬μ©λ²• (κ¶μ¥)

#### 1. μ¤ν¬λ¦½νΈ ν…ν”λ¦Ώ μ‚¬μ© (κ°€μ¥ μ•μ „)
```bash
# ν…ν”λ¦Ώμ„ λ³µμ‚¬ν•μ—¬ μƒλ΅μ΄ μ‹¤ν— μ¤ν¬λ¦½νΈ μƒμ„±
cp scripts/template_experiment.sh scripts/my_experiment.sh

# μ‹¤ν— μ΄λ¦„κ³Ό μ„¤μ •μ„ μμ •ν• ν›„ μ‹¤ν–‰
chmod +x scripts/my_experiment.sh
./scripts/my_experiment.sh
```

**ν…ν”λ¦Ώμ μ£Όμ” νΉμ§•:**
- **λ©”λ¨λ¦¬ μ•μ „**: `n_jobs=4`λ΅ μ„¤μ •ν•μ—¬ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ†ν™”
- **μλ™ λ©”λ¨λ¦¬ μ •λ¦¬**: κ° λ¨λΈ μ‹¤ν–‰ ν›„ κ°•ν™”λ λ©”λ¨λ¦¬ μ •λ¦¬
- **μ¤λ¥ ν—μ©**: ν• λ¨λΈμ΄ μ‹¤ν¨ν•΄λ„ λ‹¤μ λ¨λΈλ΅ κ³„μ† μ§„ν–‰
- **μƒμ„Έν• λ΅κΉ…**: κ° λ‹¨κ³„λ³„ λ©”λ¨λ¦¬ μƒνƒ λ° μ§„ν–‰ μƒν™© κΈ°λ΅
- **λ¨λ“ν™”λ κµ¬μ΅°**: `run_model()` ν•¨μλ΅ μ¬μ‚¬μ© κ°€λ¥ν• κµ¬μ΅°

#### 2. κΈ°μ΅΄ κ²€μ¦λ μ¤ν¬λ¦½νΈ μ‚¬μ©
```bash
# κ°λ³„ λ¨λΈ μ‹¤ν–‰ (λ©”λ¨λ¦¬ μµμ ν™”)
./scripts/run_individual_models.sh
```

**μ°Έκ³ **: ν”Όμ² μ„ νƒμ€ `configs/base/common.yaml`μ `selected_features`μ—μ„ μ¤‘μ•™ κ΄€λ¦¬λ©λ‹λ‹¤. 
ν”Όμ² μ΅°ν•©μ„ λ³€κ²½ν•λ ¤λ©΄ μ„¤μ • νμΌμ„ μμ •ν•μ„Έμ”.

#### 3. μ¤ν¬λ¦½νΈ ν…ν”λ¦Ώ μ»¤μ¤ν„°λ§μ΄μ§• κ°€μ΄λ“

**κΈ°λ³Έ μ„¤μ • μμ •:**
```bash
# λ³‘λ ¬ μ²λ¦¬ μ„¤μ • (μ‹μ¤ν…μ— λ§κ² μ΅°μ •)
N_JOBS=4  # μ•μ „ν• κ°’: 4-8, κ³ μ„±λ¥: 16-28

# λ©”λ¨λ¦¬ μ ν• μ„¤μ •
export MEMORY_LIMIT=50  # GB λ‹¨μ„

# μ‹¤ν— μ΄λ¦„ μμ •
echo "μ‹¤ν— μ‹μ‘: [μ‹¤ν— μ΄λ¦„]"  # μ›ν•λ” μ‹¤ν— μ΄λ¦„μΌλ΅ λ³€κ²½
```

**λ¨λΈ μ¶”κ°€/μ κ±°:**
```bash
# Phase 1μ— λ¨λΈ μ¶”κ°€
run_model "xgboost" "xgboost_basic" ""

# Phase 2μ— μƒλ΅μ΄ λ¦¬μƒν”λ§ λ°©λ²• μ¶”κ°€
run_model "lightgbm" "lightgbm_adasyn" "--resampling-enabled --resampling-method adasyn --resampling-ratio 0.5"
```

**μ¶”κ°€ νλΌλ―Έν„° μ„¤μ •:**
```bash
# ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹λ„ νμ μ΅°μ •
--n-trials 100  # κΈ°λ³Έκ°’, ν•„μ”μ‹ 50-200μΌλ΅ μ΅°μ •

# νƒ€μ„μ•„μ›ƒ μ„¤μ • μ¶”κ°€
--timeout 3600  # 1μ‹κ°„ νƒ€μ„μ•„μ›ƒ

# Early Stopping μ¶”κ°€
--early-stopping --early-stopping-rounds 50
```

### ConfigManager κΈ°λ° ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹¤ν–‰
```bash
# XGBoost λ¨λΈ νλ‹
python scripts/run_hyperparameter_tuning.py --model-type xgboost --experiment-type hyperparameter_tuning --nrows 10000

# CatBoost λ¨λΈ νλ‹
python scripts/run_hyperparameter_tuning.py --model-type catboost --experiment-type hyperparameter_tuning --nrows 10000

# LightGBM λ¨λΈ νλ‹
python scripts/run_hyperparameter_tuning.py --model-type lightgbm --experiment-type hyperparameter_tuning --nrows 10000

# Random Forest λ¨λΈ νλ‹
python scripts/run_hyperparameter_tuning.py --model-type random_forest --experiment-type hyperparameter_tuning --nrows 10000
```

### π€ μλ™ν™”λ μ‹¤ν—μ„ μ„ν• κ³ κΈ‰ λ…λ Ήν–‰ μΈμ μ‚¬μ©λ²•

#### κΈ°λ³Έ μΈμ
```bash
# ν•„μ μΈμ
--model-type {xgboost,lightgbm,random_forest,catboost}  # μ‚¬μ©ν•  λ¨λΈ νƒ€μ…
--experiment-type {hyperparameter_tuning,focal_loss,resampling}  # μ‹¤ν— νƒ€μ…

# λ°μ΄ν„° κ΄€λ ¨ μΈμ
--data_path PATH                    # λ°μ΄ν„° νμΌ κ²½λ΅
--nrows INT                         # μ‚¬μ©ν•  λ°μ΄ν„° ν–‰ μ (ν…μ¤νΈμ©)
```

#### κ²€μ¦ λ° λ¶„ν•  κ΄€λ ¨ μΈμ
```bash
# λ°μ΄ν„° λ¶„ν•  μ „λµ
--split-strategy {group_kfold,time_series_walk_forward,time_series_group_kfold}
--cv-folds INT                      # κµμ°¨ κ²€μ¦ ν΄λ“ μ (κΈ°λ³Έ: 5)
--test-size FLOAT                   # ν…μ¤νΈ μ„ΈνΈ λΉ„μ¨ (0.0-1.0, κΈ°λ³Έ: 0.15)
--random-state INT                  # λλ¤ μ‹λ“ (κΈ°λ³Έ: 42)
```

#### ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ΄€λ ¨ μΈμ
```bash
# νλ‹ μ„¤μ •
--n-trials INT                      # νλ‹ μ‹λ„ νμ (κΈ°λ³Έ: 100)
--tuning-direction {maximize,minimize}  # νλ‹ λ°©ν–¥
--primary-metric STR                # μ£Όμ” ν‰κ°€ μ§€ν‘ (f1, precision, recall, mcc, roc_auc, pr_auc λ“±)
--n-jobs INT                        # λ³‘λ ¬ μ²λ¦¬ μ‘μ—… μ
--timeout INT                       # νλ‹ νƒ€μ„μ•„μ›ƒ (μ΄)
```

#### Early Stopping κ΄€λ ¨ μΈμ
```bash
--early-stopping                    # Early stopping ν™μ„±ν™”
--early-stopping-rounds INT         # Early stopping λΌμ΄λ“ μ
```

#### ν”Όμ² μ„ νƒ κ΄€λ ¨ μΈμ
```bash
--feature-selection                 # ν”Όμ² μ„ νƒ ν™μ„±ν™”
--feature-selection-method {mutual_info,chi2,f_classif,recursive}  # ν”Όμ² μ„ νƒ λ°©λ²•
--feature-selection-k INT           # μ„ νƒν•  ν”Όμ² μ
```

#### λ¦¬μƒν”λ§ κ΄€λ ¨ μΈμ
```bash
--resampling-enabled                # λ¦¬μƒν”λ§ ν™μ„±ν™”
--resampling-method {smote,borderline_smote,adasyn,under_sampling,hybrid}  # λ¦¬μƒν”λ§ λ°©λ²•
--resampling-ratio FLOAT            # λ¦¬μƒν”λ§ ν›„ μ–‘μ„± ν΄λμ¤ λΉ„μ¨
```

#### MLflow λ° κ²°κ³Ό μ €μ¥ κ΄€λ ¨ μΈμ
```bash
--experiment-name STR               # MLflow μ‹¤ν— μ΄λ¦„
--save-model                        # μµμ  λ¨λΈ μ €μ¥
--save-predictions                  # μμΈ΅ κ²°κ³Ό μ €μ¥
--mlflow_ui                         # νλ‹ μ™„λ£ ν›„ MLflow UI μ‹¤ν–‰
--verbose {0,1,2}                   # λ΅κ·Έ λ λ²¨ (0: μµμ†, 1: κΈ°λ³Έ, 2: μƒμ„Έ)
```

#### μ‹¤μ©μ μΈ μ‹¤ν— μμ‹

**1. λΉ λ¥Έ ν…μ¤νΈ (μ†κ·λ¨ λ°μ΄ν„°)**
```bash
python scripts/run_hyperparameter_tuning.py \
  --model-type xgboost \
  --experiment-type hyperparameter_tuning \
  --nrows 1000 \
  --n-trials 10 \
  --cv-folds 3 \
  --verbose 2
```

**2. μ‹κ°„ κΈ°λ° λ¶„ν•  μ‹¤ν—**
```bash
python scripts/run_hyperparameter_tuning.py \
  --model-type catboost \
  --experiment-type hyperparameter_tuning \
  --split-strategy time_series_walk_forward \
  --cv-folds 5 \
  --n-trials 50 \
  --primary-metric pr_auc
```

**3. λ¦¬μƒν”λ§ λΉ„κµ μ‹¤ν—**
```bash
python scripts/run_hyperparameter_tuning.py \
  --model-type lightgbm \
  --experiment-type resampling \
  --resampling-comparison \
  --resampling-methods smote adasyn \
  --n-trials 30 \
  --cv-folds 5
```

**4. ν”Όμ² μ„ νƒ μ‹¤ν—**
```bash
python scripts/run_hyperparameter_tuning.py \
  --model-type random_forest \
  --experiment-type hyperparameter_tuning \
  --feature-selection \
  --feature-selection-method mutual_info \
  --feature-selection-k 10 \
  --n-trials 50 \
  --save-model \
  --save-predictions
```

**5. κ³ μ„±λ¥ μ‹¤ν— (μ „μ²΄ λ°μ΄ν„°)**
```bash
python scripts/run_hyperparameter_tuning.py \
  --model-type xgboost \
  --experiment-type hyperparameter_tuning \
  --n-trials 200 \
  --cv-folds 5 \
  --primary-metric f1 \
  --early-stopping \
  --early-stopping-rounds 50 \
  --save-model \
  --save-predictions \
  --mlflow_ui
```

### ConfigManager κΈ°λ° λ¦¬μƒν”λ§ λΉ„κµ μ‹¤ν— μ‹¤ν–‰ (β… μµμ‹  κΈ°λ¥)
```bash
# λ¨λ“  λ¨λΈμ— λ€ν•΄ λ¦¬μƒν”λ§ λΉ„κµ μ‹¤ν—
python scripts/run_hyperparameter_tuning.py --model-type xgboost --experiment-type resampling --resampling-comparison
python scripts/run_hyperparameter_tuning.py --model-type catboost --experiment-type resampling --resampling-comparison
python scripts/run_hyperparameter_tuning.py --model-type lightgbm --experiment-type resampling --resampling-comparison
python scripts/run_hyperparameter_tuning.py --model-type random_forest --experiment-type resampling --resampling-comparison

# νΉμ • λ¦¬μƒν”λ§ κΈ°λ²•λ§ λΉ„κµ
python scripts/run_hyperparameter_tuning.py --model-type xgboost --experiment-type resampling --resampling-comparison --resampling-methods smote adasyn

# μ‹κ³„μ—΄ νΉν™” λ¦¬μƒν”λ§ μ‹¤ν— (β… 2025-07-16 μ‹ κ· κΈ°λ¥)
python scripts/run_hyperparameter_tuning.py --model-type xgboost --experiment-type resampling --resampling-method time_series_adapted
```

### λ¦¬μƒν”λ§ ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹¤ν–‰ (β… 2025-07-16 μ‹ κ· κΈ°λ¥)
```bash
# SMOTE k_neighbors λ° sampling_strategy νλ‹
python scripts/run_hyperparameter_tuning.py --model-type xgboost --experiment-type resampling --resampling-method smote --n-trials 50

# Borderline SMOTE νλΌλ―Έν„° νλ‹
python scripts/run_hyperparameter_tuning.py --model-type catboost --experiment-type resampling --resampling-method borderline_smote --n-trials 50

# ADASYN νλΌλ―Έν„° νλ‹
python scripts/run_hyperparameter_tuning.py --model-type lightgbm --experiment-type resampling --resampling-method adasyn --n-trials 50

# μ‹κ³„μ—΄ νΉν™” λ¦¬μƒν”λ§ νλΌλ―Έν„° νλ‹
python scripts/run_hyperparameter_tuning.py --model-type random_forest --experiment-type resampling --resampling-method time_series_adapted --n-trials 50
```

### λ κ±°μ‹ λ‹¨μΌ νμΌ config μ‚¬μ© (λ°±μ›λ“ νΈν™μ„±)
```bash
python scripts/run_hyperparameter_tuning.py --tuning_config configs/hyperparameter_tuning.yaml --base_config configs/default_config.yaml
```

## μƒμ„±λλ” νμΌλ“¤

### λ¶„μ„ κ²°κ³Ό (data/sourcedata_analysis/)
- **figures/**: 7κ°μ λ¶„μ„ κ·Έλν”„ (PNG)
- **reports/**: 6κ°μ λ¶„μ„ λ¦¬ν¬νΈ (TXT)

### μ „μ²λ¦¬ λ°μ΄ν„° (data/processed/)
- **processed_data_with_features.csv**: ν”Όμ² μ—”μ§€λ‹μ–΄λ§μ΄ μ™„λ£λ λ°μ΄ν„°

### μ‹¤ν— κ²°κ³Ό (MLflow)
- **μ‹¤ν— νλΌλ―Έν„°**: μ„¤μ • νμΌμ λ¨λ“  νλΌλ―Έν„°
- **ν΄λ“λ³„ λ©”νΈλ¦­**: κ° κµμ°¨ κ²€μ¦ ν΄λ“μ μ„±λ¥ μ§€ν‘
- **κ³ κΈ‰ ν‰κ°€ μ§€ν‘**: Balanced Accuracy, Precision-Recall Curve, ROC-AUC vs PR-AUC λΉ„κµ
- **λ¨λΈ μ•„ν‹°ν©νΈ**: ν•™μµλ λ¨λΈ λ° κ²°κ³Ό μ”μ•½

### νλ‹ κ²°κ³Ό (models/)
- **best_tuned_model.joblib**: μµμ  νλΌλ―Έν„°λ΅ ν•™μµλ λ¨λΈ
- **optuna_study.pkl**: Optuna study κ°μ²΄
- **optimization_plots.png**: νλ‹ κ³Όμ • μ‹κ°ν™”

## μ£Όμ” νΉμ§•

### λ°μ΄ν„° νΉμ„±
- **κ·λ¨**: 1,569,071 ν–‰ Γ— 15 μ—΄
- **κ°μΈ μ**: 269,339λ…
- **κΈ°κ°„**: 2015-2024 (10λ…„)
- **μ‹κ³„μ—΄ κΈΈμ΄**: ν‰κ·  5.79λ…„/κ°μΈ

### μμΈ΅ λ©ν‘
- **μ—°μ†ν•**: anxiety_score, depress_score, sleep_score
- **μ΄μ§„ν•**: suicide_t (μμ‚΄ μ‚¬κ³ ), suicide_a (μμ‚΄ μ‹λ„)

### μ£Όμ” λ„μ „κ³Όμ 
- **κ·Ήλ„ λ¶κ· ν•**: μμ‚΄ μ‹λ„ 0.12% (849:1)
- **μ‹κ³„μ—΄ λ‹¤μ–‘μ„±**: κ°μΈλ³„ μ‹κ³„μ—΄ κΈΈμ΄ 1-10λ…„
- **λ°μ΄ν„° ν’μ§**: μΌλ¶€ μ΄μƒμΉ λ° κ²°μΈ΅μΉ μ΅΄μ¬

### κµ¬ν„λ λ¨λΈ (β… 4κ° λ¨λΈ μ™„λ£)
- **XGBoost λ¨λΈ**: κ·Ήλ‹¨μ  λ¶κ· ν• λ°μ΄ν„° μ²λ¦¬ (μ •ν™•λ„ 99.87%)
- **CatBoost λ¨λΈ**: λ²”μ£Όν• λ³€μ μ²λ¦¬ κ°•μ , κ· ν•μ΅ν μ„±λ¥ (μ •ν™•λ„ 85%, AUC-ROC 0.91)
- **LightGBM λ¨λΈ**: λΉ λ¥Έ ν•™μµ μ†λ„μ™€ λ†’μ€ μ„±λ¥ (μ •ν™•λ„ 84%, AUC-ROC 0.90)
- **Random Forest λ¨λΈ**: ν•΄μ„ κ°€λ¥μ„±κ³Ό μ•μ •μ„± (μ •ν™•λ„ 83%, AUC-ROC 0.89)
- **λ¨λΈ μ•„ν‚¤ν…μ² ν‘μ¤€ν™”**: BaseModel μ¶”μƒ ν΄λμ¤μ™€ ModelFactoryλ¥Ό ν†µν• μΌκ΄€λ μΈν„°νμ΄μ¤
- **λ¨λΈλ³„ λ°μ΄ν„° κ²€μ¦ μµμ ν™”**: κ° λ¨λΈμ νΉμ„±μ— λ§λ” `_validate_input_data` λ©”μ„λ“ μ¤λ²„λΌμ΄λ“
  - XGBoost: λ²”μ£Όν• λ³€μλ¥Ό μ«μλ΅ λ³€ν™ (XGBoost νΈν™μ„±)
  - CatBoost/LightGBM/Random Forest: λ²”μ£Όν• λ³€μ λ³΄μ΅΄ (λ¨λΈ μμ²΄ μ²λ¦¬)

### ν‰κ°€ μ‹μ¤ν… κ°μ„  (β… μµμ‹  μ—…λ°μ΄νΈ)
- **μ¤‘μ•™ν™”λ ν‰κ°€ λ΅μ§**: `evaluation.py`μ `calculate_all_metrics`κ°€ λ¨λ“  ν‰κ°€μ λ‹¨μΌ μ§„μ…μ 
- **λ³µμ΅ν• μ»¬λΌ λ§¤μΉ­**: μ „μ²λ¦¬ ν›„ μ»¬λΌλ… λ³€κ²½(`remainder__`, `pass__`, `num__`, `cat__` μ ‘λ‘μ‚¬)μ—λ„ μ•μ •μ  λ§¤μΉ­
- **μ„¤μ • κΈ°λ° νƒ€κ² νƒ€μ… μ •μ**: ν•λ“μ½”λ”©λ λ΅μ§ λ€μ‹  `configs/base/common.yaml`μ `target_types` μ„Ήμ…μ—μ„ λ…μ‹μ  μ •μ
- **λ‹¤μ¤‘ νƒ€κ² μ§€μ›**: κ° νƒ€κ²λ³„λ΅ κ°λ³„ ν‰κ°€ μν–‰ ν›„ ν†µν•© κ²°κ³Ό λ°ν™
- **νƒ€κ²λ³„ λ©”νΈλ¦­ κµ¬μ΅°**: ν‰λ©΄ν™”λ λ©”νΈλ¦­μ—μ„ νƒ€κ²λ³„ κµ¬μ΅°ν™”λ λ©”νΈλ¦­μΌλ΅ κ°μ„ 
- **ν™•μ¥λ ν‰κ°€ μ§€ν‘**: 10κ° μ¶”κ°€ λ©”νΈλ¦­ (MCC, Kappa, Specificity, NPV, FPR, FNR λ“±)

### π€ μλ™ν™”λ μ‹¤ν— μ‹μ¤ν… (β… μµμ‹  κΈ°λ¥)
- **λ…λ Ήν–‰ μΈμ κΈ°λ° μ‹¤ν— μ μ–΄**: 20κ° μ΄μƒμ μΈμλ΅ μ‹¤ν— μ™„μ „ μλ™ν™”
- **ConfigManager κΈ°λ° μ„¤μ • κ΄€λ¦¬**: κ³„μΈµμ  μ„¤μ • νμΌ μλ™ λ³‘ν•© λ° κ²€μ¦
- **μ μ—°ν• λ°μ΄ν„° λ¶„ν• **: 3κ°€μ§€ λ¶„ν•  μ „λµ (group_kfold, time_series_walk_forward, time_series_group_kfold)
- **κ³ κΈ‰ ν•μ΄νΌνλΌλ―Έν„° νλ‹**: Optuna κΈ°λ° μµμ ν™”, Early Stopping, νƒ€μ„μ•„μ›ƒ μ§€μ›
- **ν”Όμ² μ„ νƒ μλ™ν™”**: Mutual Info, Chi2, F-test, Recursive Feature Elimination μ§€μ›
- **λ¦¬μƒν”λ§ μ‹¤ν— ν†µν•©**: SMOTE, ADASYN, Borderline SMOTE λ“± λΉ„κµ μ‹¤ν—
- **MLflow μ‹¤ν— μ¶”μ **: λ¨λ“  μ‹¤ν— κ²°κ³Ό μλ™ λ΅κΉ… λ° μ‹κ°ν™”
- **κ²°κ³Ό μ €μ¥ μλ™ν™”**: λ¨λΈ, μμΈ΅ κ²°κ³Ό, μ‹κ°ν™” μλ™ μ €μ¥

### π”„ λ¦¬μƒν”λ§ μ‹μ¤ν… (β… 2025-07-16 λ€ν­ κ°μ„ )
- **7κ°€μ§€ λ¦¬μƒν”λ§ κΈ°λ²• μ§€μ›**: none, smote, borderline_smote, adasyn, under_sampling, hybrid, time_series_adapted
- **ν•μ΄νΌνλΌλ―Έν„° νλ‹ ν†µν•©**: k_neighbors, sampling_strategy λ“± λ¦¬μƒν”λ§ νλΌλ―Έν„°λ„ Optunaλ΅ μλ™ νλ‹
- **μ‹κ³„μ—΄ νΉν™” λ¦¬μƒν”λ§**: time_weight, temporal_window, seasonality_weight λ“± 5κ° νλΌλ―Έν„°λ΅ μ‹κ°„μ  μΆ…μ†μ„± κ³ λ ¤
- **κ·Ήλ„ λ¶κ· ν• λ°μ΄ν„° λ€μ‘**: 849:1 λ¶κ· ν• λΉ„μ¨μ— μµμ ν™”λ νλΌλ―Έν„° λ²”μ„ μ„¤μ •
- **MLflow μλ™ λ΅κΉ…**: λ¨λ“  λ¦¬μƒν”λ§ νλΌλ―Έν„°μ™€ κ²°κ³Όκ°€ MLflowμ— μλ™ κΈ°λ΅
- **ConfigManager μ—°λ™**: λ¦¬μƒν”λ§ μ„¤μ •μ΄ κ³„μΈµμ  config μ‹μ¤ν…κ³Ό μ™„μ „ ν†µν•©

### λ¶κ· ν• λ°μ΄ν„° μ²λ¦¬
- **ν΄λμ¤ κ°€μ¤‘μΉ, scale_pos_weight**: XGBoost λ“±μ—μ„ λ¶κ· ν• λ°μ΄ν„° μ²λ¦¬λ¥Ό μ„ν• κ°€μ¤‘μΉ μµμ… μ§€μ›

### μ ν‹Έλ¦¬ν‹° ν•¨μ (β… μµμ‹  μ¶”κ°€)
- **μ«μ λ³€ν™ λ° κ²€μ¦**: `safe_float_conversion()`, `is_valid_number()` ν•¨μλ΅ ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ³Όμ •μ—μ„ μ•μ „ν• μ«μ μ²λ¦¬
- **λ°μ΄ν„° ν’μ§ λ³΄μ¥**: NaN/Inf κ°’ μλ™ κ°μ§€ λ° μ²λ¦¬λ΅ νλ‹ κ³Όμ •μ μ•μ •μ„± ν–¥μƒ

### λ°μ΄ν„° ν’μ§ κ²€μ¦ μ‹μ¤ν… (β… 2025-07-16 μ‹ κ· μ¶”κ°€)
- **Inf κ°’ κ²€μ¦**: λ¨λ“  μμΉν• μ»¬λΌμ—μ„ λ¬΄ν•λ€ κ°’ μλ™ κ°μ§€ λ° λ³΄κ³ 
- **λ°μ΄ν„° νƒ€μ… νΌμ¬ κ²€μ¦**: μμΉν• μ»¬λΌμ—μ„ λ¬Έμμ—΄ νΌμ¬ μ—¬λ¶€ κ²€μ¦
- **νμ΄ν”„λΌμΈ ν’μ§ κ²€μ¦**: ν”Όμ² μ—”μ§€λ‹μ–΄λ§ β†’ μ „μ²λ¦¬ κ³Όμ •μ—μ„ NaN/Inf κ°’ λ³€ν™” μ¶”μ 
- **μλ™ν™”λ ν’μ§ λ¦¬ν¬νΈ**: `infinite_values_analysis.txt`, `data_type_mixture_analysis.txt` μλ™ μƒμ„±

### μµμ‹  μ‹¤ν— κ²°κ³Ό
- **2025-01-XX κΈ°μ¤€, λ¨λΈλ³„ λ°μ΄ν„° κ²€μ¦ μµμ ν™” λ° ν‰κ°€ λ΅μ§ μ¤‘μ•™ν™” μ™„λ£**
- **2025-06-25 κΈ°μ¤€, μ«μ κ²€μ¦ μ ν‹Έλ¦¬ν‹° ν•¨μ μ¶”κ°€λ΅ ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ•μ •μ„± ν–¥μƒ**
- **2025-06-24 κΈ°μ¤€, XGBoost, CatBoost, LightGBM, Random Forest 4κ° λ¨λΈ λ¨λ‘ ConfigManager κΈ°λ° ν•μ΄νΌνλΌλ―Έν„° νλ‹ λ° μ „μ²΄ νμ΄ν”„λΌμΈ μ •μƒ λ™μ‘ ν™•μΈ**
- **nrows μµμ…μ„ ν†µν• λ¶€λ¶„ λ°μ΄ν„° μ‹¤ν— μ •μƒ λ™μ‘ ν™•μΈ**
- **νƒ€κ² μ»¬λΌ λ§¤μΉ­ λ΅μ§ κ°μ„ **: μ „μ²λ¦¬ ν›„ μ»¬λΌλ… λ³€κ²½(pass__, num__, cat__ μ ‘λ‘μ‚¬)μ—λ„ λ¨λ“  λ¨λΈμ—μ„ νƒ€κ² μΈμ‹ λ° ν•™μµ/μμΈ΅ μ •μƒ λ™μ‘
- **λ¶„λ¥/νκ·€ μλ™ λ¶„κΈ° κ°μ„ **: λ¨λ“  λ¨λΈμ—μ„ νƒ€κ² νƒ€μ…μ— λ”°λΌ μλ™μΌλ΅ λ¶„λ¥/νκ·€ νλΌλ―Έν„° μ μ© (LightGBM: binary/binary_logloss, Random Forest: gini/mse)
- **λ¨λΈλ³„ νλΌλ―Έν„° μ²λ¦¬ μµμ ν™”**: 
  - LightGBM: focal_loss νλΌλ―Έν„° μ κ±°, νƒ€κ² μ ‘λ‘μ‚¬ μ²λ¦¬
  - Random Forest: sample_weight λ¶„λ¦¬, λ¶„λ¥/νκ·€λ³„ νλΌλ―Έν„° ν•„ν„°λ§
- **MLflow κΈ°λ΅ μ •μƒν™”**: λ¨λ“  λ¨λΈμ—μ„ νλΌλ―Έν„°, λ©”νΈλ¦­, μ•„ν‹°ν©νΈ μ •μƒ κΈ°λ΅ ν™•μΈ
- **κ·Ήλ‹¨μ  λ¶κ· ν• λ°μ΄ν„°**: μμ‚΄ μ‹λ„ 0.12%λ΅ μΈν•΄ F1-score λ“± μ£Όμ” λ¶„λ¥ μ„±λ¥μ€ 0.0μ— μλ ΄(λ¨λΈ κµ¬μ΅°/νμ΄ν”„λΌμΈ λ¬Έμ  μ•„λ‹)
- **nrows μµμ… λ―Έμ§€μ • μ‹ μ „μ²΄ λ°μ΄ν„° μ‚¬μ©, μ§€μ • μ‹ λ¶€λ¶„ λ°μ΄ν„°λ§ μ‚¬μ©**
- **νμ΄ν”„λΌμΈ κµ¬μ΅° μ•μ •ν™”**: μ‹¤ν— κ²°κ³Ό, νμ΄ν”„λΌμΈ/λ¨λΈ κµ¬μ΅°/MLflow μ—°λ™/κ²°κ³Ό μ €μ¥ λ“± λ¨λ“  μ‹μ¤ν…μ΄ μ•μ •μ μΌλ΅ λ™μ‘

### λ¨λΈλ³„ λ³‘λ ¬μ²λ¦¬ μµμ ν™”
- **XGBoost(n_jobs=28), LightGBM(num_threads=28), CatBoost(thread_count=28), Random Forest(n_jobs=28)λ΅ λ¨λ“  λ¨λΈμ λ³‘λ ¬μ²λ¦¬ μ½”μ–΄ μλ¥Ό ν†µμΌν•μ—¬ μ‹¤ν—μ μΌκ΄€μ„±κ³Ό μ„±λ¥μ„ μµμ ν™”ν•¨

## μ‹¤ν— κ΄€λ¦¬ λ° λ°μ΄ν„° λ¶„ν•  μ „λµ

### μ‹¤ν— κ΄€λ¦¬ μ‹μ¤ν…
- μ‹¤ν— κ΄€λ¦¬ λ° λ°μ΄ν„° λ¶„ν•  νμ΄ν”„λΌμΈμ€ `src/splits.py`μ™€ `scripts/run_hyperparameter_tuning.py`λ΅ κµ¬ν„λμ–΄ μμµλ‹λ‹¤.
- μ‹¤ν— μ„¤μ •μ€ κ³„μΈµμ  config μ²΄κ³„μ—μ„ μΌκ΄€μ μΌλ΅ κ΄€λ¦¬ν•λ©°, λ‹¤μ–‘ν• λ¶„ν•  μ „λµμ„ ν• κ³³μ—μ„ μ‰½κ² μ „ν™ν•  μ μμµλ‹λ‹¤.
- MLflowλ¥Ό ν™μ©ν•΄ μ‹¤ν—λ³„, ν΄λ“λ³„, μ „λµλ³„ κ²°κ³Όλ¥Ό μ²΄κ³„μ μΌλ΅ κΈ°λ΅ λ° μ¶”μ ν•©λ‹λ‹¤.

### μ§€μ›ν•λ” λ°μ΄ν„° λ¶„ν•  μ „λµ
- **ID κΈ°λ° μµμΆ… ν…μ¤νΈ μ„ΈνΈ λ¶„λ¦¬**: GroupShuffleSplitμ„ ν™μ©ν•΄ train/valκ³Ό testμ IDκ°€ μ λ€ κ²ΉμΉμ§€ μ•λ„λ΅ λ¶„λ¦¬. ν…μ¤νΈ μ„ΈνΈλ” μ¤μ§ μµμΆ… ν‰κ°€μ—λ§ μ‚¬μ©λλ©°, κµμ°¨ κ²€μ¦ λ° λ¨λΈ κ°λ° κ³Όμ •μ—μ„λ” μ‚¬μ©ν•μ§€ μ•μµλ‹λ‹¤.
- **κµμ°¨ κ²€μ¦ μ „λµ**
    - `time_series_walk_forward`: μ—°λ„λ³„λ΅ κ³Όκ±° λ°μ΄ν„°λ¥Ό λ„μ  ν•™μµ, λ―Έλ μ—°λ„ κ²€μ¦. κ° ν΄λ“ λ‚΄μ—μ„λ„ ID κΈ°λ° λ¶„ν•  μ μ©.
    - `time_series_group_kfold`: IDμ™€ μ‹κ°„ μμ„λ¥Ό λ¨λ‘ κ³ λ ¤ν• K-Fold. κ° ν΄λ“ λ‚΄μ—μ„ IDκ°€ κ²ΉμΉμ§€ μ•μΌλ©΄μ„, κ²€μ¦ λ°μ΄ν„°λ” ν•­μƒ ν›λ ¨ λ°μ΄ν„°λ³΄λ‹¤ λ―Έλ μ‹μ λ§ ν¬ν•¨.
    - `group_kfold`: μμν•κ² IDλ§ κΈ°μ¤€μΌλ΅ ν΄λ“λ¥Ό λ‚λ„λ” μ „λµ. μ‹κ°„ μμ„λ” λ³΄μ¥ν•μ§€ μ•μ.

#### λ¶„ν•  μ „λµ μ „ν™ λ°©λ²•
- κ³„μΈµμ  config μ²΄κ³„μ `configs/base/validation.yaml`μ—μ„ `strategy` κ°’μ„ μ•„λ μ¤‘ ν•λ‚λ΅ λ³€κ²½ν•λ©΄ λ©λ‹λ‹¤:
    - `time_series_walk_forward`
    - `time_series_group_kfold`
    - `group_kfold`

#### μ‹¤ν— μ‹¤ν–‰ μμ‹
```bash
python scripts/run_hyperparameter_tuning.py --model-type xgboost --experiment-type default
```
- MLflow UIμ—μ„ κ° μ „λµλ³„, ν΄λ“λ³„ μ‹¤ν— κ²°κ³Όμ™€ μ•„ν‹°ν©νΈ(ν΄λ“ μ”μ•½, ν…μ¤νΈ μ„ΈνΈ μ •λ³΄ λ“±)λ¥Ό ν™•μΈν•  μ μμµλ‹λ‹¤.
- ν…μ¤νΈ μ„ΈνΈλ” μ¤μ§ μµμΆ… λ¨λΈ ν‰κ°€ μ‹μ—λ§ μ‚¬μ©λλ©°, κµμ°¨ κ²€μ¦ λ° λ¨λΈ κ°λ° κ³Όμ •μ—μ„λ” μ‚¬μ©ν•μ§€ μ•μµλ‹λ‹¤.

## ML νμ΄ν”„λΌμΈ κµ¬μ„±

### μ „μ²λ¦¬ νμ΄ν”„λΌμΈ
- **μ‹κ³„μ—΄ λ³΄κ°„**: κ°μΈλ³„ ffill/bfill μ „λµ
- **κ²°μΈ΅μΉ μ²λ¦¬**: μμΉν•(mean), λ²”μ£Όν•(most_frequent)
- **κ²°μΈ΅μΉ ν”λκ·Έ(Flag) μƒμ„±**: μ£Όμ” μ‹κ³„μ—΄ μ μ(`anxiety_score`, `depress_score`, `sleep_score` λ“±)μ— λ€ν•΄ κ²°μΈ΅κ°’μ΄ μ΅΄μ¬ν•λ” ν–‰μ„ μ‚¬μ „μ— κ°μ§€ν•μ—¬, κ° μ μλ³„λ΅ `*_missing_flag` μ»¬λΌμ„ μƒμ„±ν•©λ‹λ‹¤. μ΄ ν”λκ·Έλ” κ²°μΈ΅μΉ λ³΄κ°„/λ€μ²΄ μ „μ— μ¶”κ°€λλ©°, μ΄ν›„ νμ΄ν”„λΌμΈ μ „μ²΄μ—μ„ λ³΄μ΅΄λμ–΄ κ²°μΈ΅ μμ²΄μ μ„μƒμ  μλ―Έλ¥Ό ν”Όμ²λ΅ ν™μ©ν•  μ μμµλ‹λ‹¤. ν”λκ·Έ μƒμ„± λ€μƒ μ»¬λΌμ€ config(`configs/base/common.yaml`)μ—μ„ κ΄€λ¦¬λλ©°, passthrough μ»¬λΌμΌλ΅ μ§€μ •λμ–΄ λ¨λ“  λ¨λΈ μ…λ ¥μ— μ „λ‹¬λ©λ‹λ‹¤.
- **λ²”μ£Όν• μΈμ½”λ”©**: OrdinalEncoder (XGBoost νΈν™, μ•μ •ν™” μ™„λ£)
- **λ°μ΄ν„° νƒ€μ… λ³€ν™**: XGBoost νΈν™μ„ μ„ν• float32 λ³€ν™

### ν”Όμ² μ—”μ§€λ‹μ–΄λ§
- **μ‹κ°„ κΈ°λ° ν”Όμ²**: μ›”, μ”μΌ, μ—°λ„ λ‚΄ κ²½κ³ΌμΌ
- **κ³Όκ±° μ΄λ ¥ ν”Όμ²**: 2λ…„ μ΄λ™ν‰κ· , μ΄λ™ν‘μ¤€νΈμ°¨, μ „λ…„ λ€λΉ„ λ³€ν™”λ‰
- **λ°μ΄ν„° μ μ¶ κ²€μ¦**: κΈ°μ΅΄ ν”Όμ²μ λ―Έλ μ •λ³΄ μ°Έμ΅° μ—¬λ¶€ ν™•μΈ

### XGBoost λ¨λΈ (μ•μ •ν™” μ™„λ£)
- **λ‹¤μ¤‘ μ¶λ ¥ μ§€μ›**: νκ·€(μ μ) + λ¶„λ¥(μμ‚΄ μ—¬λ¶€)
- **Early Stopping**: κ³Όμ ν•© λ°©μ§€ (XGBoost 1.7.6 νΈν™)
- **λ¶κ· ν• μ²λ¦¬**: scale_pos_weight μλ™ κ³„μ‚°
- **ν”Όμ² μ¤‘μ”λ„**: λ¨λΈ ν•΄μ„μ„ μ„ν• μ¤‘μ”λ„ μ¶”μ¶
- **νλΌλ―Έν„° μ „λ‹¬ μ•μ •ν™”**: λ¨λΈ μƒμ„± μ‹μ™€ fit μ‹ νλΌλ―Έν„° λ¶„λ¦¬ κ΄€λ¦¬

### ν›λ ¨ λ° ν‰κ°€
- **κµμ°¨ κ²€μ¦**: λ‹¤μ–‘ν• μ „λµ μ§€μ›
- **λ°μ΄ν„° μ μ¶ λ°©μ§€**: ν΄λ“λ³„ μ „μ²λ¦¬ νμ΄ν”„λΌμΈ μ¬ν•™μµ
- **νƒ€κ² κ²°μΈ΅μΉ μλ™ μ²λ¦¬**: ν•™μµ/κ²€μ¦ λ°μ΄ν„°μ—μ„ κ²°μΈ΅μΉκ°€ μλ” μƒν” μλ™ μ κ±°
- **κΈ°λ³Έ μ„±λ¥ μ§€ν‘**: MAE, RMSE, RΒ² (νκ·€) / Precision, Recall, F1, ROC-AUC (λ¶„λ¥)
- **κ³ κΈ‰ ν‰κ°€ μ§€ν‘**: Balanced Accuracy, Precision-Recall Curve, μµμ  μ„κ³„κ°’ νƒμƒ‰
- **MLflow λ΅κΉ…**: μ‹¤ν— μ¶”μ  λ° κ²°κ³Ό μ €μ¥

### ν•μ΄νΌνλΌλ―Έν„° νλ‹
- **Optuna κΈ°λ° μµμ ν™”**: λ‹¤μ–‘ν• μƒν”λ¬(TPE, Random, Grid Search) μ§€μ›
- **κµμ°¨ κ²€μ¦ ν†µν•©**: νλ‹ κ³Όμ •μ—μ„ κµμ°¨ κ²€μ¦μ„ ν†µν• μ•μ •μ  μ„±λ¥ ν‰κ°€
- **κ³ κΈ‰ ν‰κ°€ μ§€ν‘**: νλ‹ κ³Όμ •μ—μ„λ„ λ¨λ“  κ³ κΈ‰ μ§€ν‘ κ³„μ‚° λ° λ΅κΉ…
- **μ‹κ°ν™” μƒμ„±**: μµμ ν™” κ³Όμ •, νλΌλ―Έν„° μ¤‘μ”λ„, λ³‘λ ¬ μΆν‘ ν”λ΅― λ“±

## Optuna ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹κ°ν™”μ MLflow κΈ°λ΅ μ§€μ› (2025-07-12 μµμ‹ )

- **Optuna νλ‹ μ‹κ°ν™”(ν”λ΅―) μλ™ κΈ°λ΅**: ν•μ΄νΌνλΌλ―Έν„° νλ‹μ΄ λλ‚λ©΄ Optunaμ μ£Όμ” μ‹κ°ν™”(μµμ ν™” νμ¤ν† λ¦¬, νλΌλ―Έν„° μ¤‘μ”λ„, λ³‘λ ¬μΆν‘, μ¬λΌμ΄μ¤, μ»¨ν¬μ–΄ λ“±)κ°€ μλ™μΌλ΅ μƒμ„±λμ–΄ MLflowμ— μ•„ν‹°ν©νΈ(optuna_plots ν΄λ”)λ΅ μ €μ¥λ©λ‹λ‹¤.
- **MLflow UIμ—μ„ ν™•μΈ**: κ° μ‹¤ν— runμ μ•„ν‹°ν©νΈ(optuna_plots)μ—μ„ λ¨λ“  νλ‹ ν”λ΅―μ„ μ›Ήμ—μ„ λ°”λ΅ ν™•μΈν•  μ μμµλ‹λ‹¤.
- **μ§€μ› ν”λ΅― μΆ…λ¥**: optimization_history, param_importances, parallel_coordinate, slice_plot, contour_plot, param_importances_duration λ“±
- **μμ‹ μ½”λ“**:

```python
import optuna
import matplotlib.pyplot as plt
import mlflow

# study = optuna.create_study(...)
# study.optimize(...)

optuna.visualization.matplotlib.plot_optimization_history(study)
plt.savefig("optimization_history.png")
plt.close()
mlflow.log_artifact("optimization_history.png", artifact_path="optuna_plots")
```

- **ν”„λ΅μ νΈ λ‚΄ μλ™ν™”**: `src/hyperparameter_tuning.py`μ log_optuna_visualizations_to_mlflow ν•¨μμ—μ„ μλ™ μ²λ¦¬λ¨.

## μ½”λ“ ν’μ§ λ° μ•μ •μ„±

### μµκ·Ό κ°μ„ μ‚¬ν•­
- **μ«μ κ²€μ¦ μ ν‹Έλ¦¬ν‹° μ¶”κ°€**: `safe_float_conversion()`, `is_valid_number()` ν•¨μλ΅ ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ³Όμ •μ—μ„ μ•μ „ν• μ«μ μ²λ¦¬ λ° NaN/Inf κ°’ μλ™ κ°μ§€
- **λ¨λ“  κ³ κΈ‰ λ¨λΈ κµ¬ν„ μ™„λ£**: CatBoost, LightGBM, Random Forest λ¨λΈ ν΄λμ¤ κµ¬ν„ λ° ν…μ¤νΈ μ™„λ£
- **λ¨λΈ μ•„ν‚¤ν…μ² ν‘μ¤€ν™”**: BaseModel μ¶”μƒ ν΄λμ¤μ™€ ModelFactoryλ¥Ό ν†µν• μΌκ΄€λ λ¨λΈ μΈν„°νμ΄μ¤ κµ¬μ¶•
- **ν†µν•© μ‹¤ν— νμ΄ν”„λΌμΈ**: λ‹¤μ–‘ν• λ¨λΈμ„ λ™μΌν• νμ΄ν”„λΌμΈμ—μ„ μ‹¤ν— κ°€λ¥ν• κµ¬μ΅° μ™„μ„±
- **λ¨λΈλ³„ μ„±λ¥ κ²€μ¦**: 
  - CatBoost: 85% μ •ν™•λ„, 0.91 AUC-ROC (μµκ³  μ„±λ¥)
  - LightGBM: 84% μ •ν™•λ„, 0.90 AUC-ROC (μ°μν• μ„±λ¥)
  - Random Forest: 83% μ •ν™•λ„, 0.89 AUC-ROC (μ•μ •μ  μ„±λ¥)
- **ConfigManager κΈ°λ° λ¦¬μƒν”λ§ λΉ„κµ μ‹¤ν—**: κ³„μΈµμ  config μ‹μ¤ν…μ„ ν™μ©ν• λ¦¬μƒν”λ§ κΈ°λ²• λΉ„κµ λ° ν•μ΄νΌνλΌλ―Έν„° νλ‹ ν†µν•© μ™„μ„±
- **MLflow μ¤‘μ²© μ‹¤ν–‰ λ¬Έμ  ν•΄κ²°**: λ¦¬μƒν”λ§ λΉ„κµ μ‹¤ν—μ—μ„ MLflow run μ¶©λ λ°©μ§€

### ν™κ²½ νΈν™μ„± λ° μ‹¤ν— κ΄€λ¦¬ μ‹μ¤ν… μ™„μ„±
- **XGBoost λ²„μ „ μ¶©λ ν•΄κ²°**: condaμ™€ pip κ°„ λ²„μ „ μ¶©λ λ¬Έμ  μ™„μ „ ν•΄κ²°
- **NumPy νΈν™μ„± λ¬Έμ  ν•΄κ²°**: NumPy 1.26.4λ΅ λ‹¤μ΄κ·Έλ μ΄λ“ν•μ—¬ MLflow UI μ‹¤ν–‰ κ°€λ¥
- **μ‹¤ν— νλΌλ―Έν„° μ¶”μ  μ‹μ¤ν… κ³ λ„ν™”**: configμ—μ„ λ¨λ“  XGBoost νλΌλ―Έν„°κ°€ MLflowμ— μƒμ„Έ λ΅κΉ…
- **MLflow UI μ•μ •ν™”**: λ¨λ“  config νλΌλ―Έν„°κ°€ μ›Ή UIμ—μ„ ν™•μΈ κ°€λ¥
- **νλΌλ―Έν„° μ μ© κ²€μ¦**: μ‹¤μ  λ¨λΈμ— μ μ©λλ” νλΌλ―Έν„°μ™€ config νλΌλ―Έν„° μΌμΉμ„± ν™•μΈ

### λ³‘λ ¬μ²λ¦¬ μΌκ΄€μ„±
- **λ¨λ“  λ¨λΈμ λ³‘λ ¬μ²λ¦¬ νλΌλ―Έν„°λ¥Ό 28λ΅ ν†µμΌν•μ—¬ μ‹¤ν— ν™κ²½μ μΌκ΄€μ„±κ³Ό μ‹μ¤ν… μμ› ν™μ©μ„ κ·Ήλ€ν™”

### μ„±λ¥ μ§€ν‘ (μµμ‹  μ‹¤ν— κ²°κ³Ό)
- **κµμ°¨ κ²€μ¦ μ„±κ³µ**: 5κ° ν΄λ“μ—μ„ λ¨λ‘ μ •μƒ ν•™μµ μ™„λ£
- **Early Stopping μ •μƒ λ™μ‘**: κ³Όμ ν•© λ°©μ§€λ¥Ό μ„ν• μ΅°κΈ° μΆ…λ£ κΈ°λ¥ ν™μ„±ν™”
- **κ·Ήλ„ λ¶κ· ν• λ°μ΄ν„° μ²λ¦¬**: μμ‚΄ μ‹λ„ μμΈ΅μ 849:1 λ¶κ· ν• μƒν™©μ—μ„ μ•μ •μ  λ™μ‘
- **κΈ°λ³Έ μ§€ν‘**:
  - μ •ν™•λ„: 99.87% (λ¶κ· ν• λ°μ΄ν„° νΉμ„± λ°μ)
  - μ¬ν„μ¨/μ •λ°€λ„/F1: 0.0 (μ†μ ν΄λμ¤ μμΈ΅ μ–΄λ ¤μ›€)
- **κ³ κΈ‰ μ§€ν‘**:
  - Balanced Accuracy: 0.5011 Β± 0.0009
  - Positive Ratio: 0.0012 Β± 0.00004
  - ν΄λ“λ³„ μ„±λ¥ λ³€λ™μ„±: λ‚®μ (μ•μ •μ  μ„±λ¥)

## β οΈ SMOTE μ μ© λ¬Έμ  λ° ν•΄κ²° λ‚΄μ—­ (2025-07)

### λ¬Έμ  μ›μΈ
- SMOTEκ°€ μ •μƒμ μΌλ΅ λ™μ‘ν•μ§€ μ•κ³ , λ΅κ·Έμ— 'ID μ»¬λΌμ΄ Xμ— μ—†μµλ‹λ‹¤. λ¦¬μƒν”λ§μ„ κ±΄λ„λλ‹λ‹¤.' κ²½κ³ κ°€ λ°μƒν•¨
- feature selectionμ—μ„ selected_featuresλ§ μ“Έ λ• id μ»¬λΌμ΄ feature setμ— ν¬ν•¨λμ§€ μ•μ•„ SMOTEκ°€ id κΈ°λ° κ·Έλ£Ήν•‘μ„ λ»ν•¨
- Random Forestμ—μ„ max_features='auto'κ°€ μµμ‹  scikit-learnμ—μ„ μ§€μ›λμ§€ μ•μ•„ μ—λ¬ λ°μƒ

### ν•΄κ²° λ°©λ²•
- feature_engineering.pyμ get_feature_columns ν•¨μμ—μ„ selected_featuresλ§ μ“Έ λ•λ„ id μ»¬λΌμ΄ ν•­μƒ ν¬ν•¨λλ„λ΅ μμ •
- configs/experiments/resampling.yamlμ—μ„ random_forest_paramsμ max_featuresμ—μ„ 'auto'λ¥Ό μ κ±°ν•κ³  ['sqrt', 'log2', 'None']λ§ ν—μ©
- μ „μ²΄ Phase 3(SMOTE) μ‹¤ν—μ—μ„ --nrows μΈμ μ—†μ΄ μ „μ²΄ λ°μ΄ν„°λ΅ n_trials=100 μ‹¤ν—μ΄ λλ„λ΅ μ¤ν¬λ¦½νΈ μ κ²€

### μ μ© νμΌ
- src/feature_engineering.py
- configs/experiments/resampling.yaml
- scripts/run_individual_models.sh (κµ¬μ΅° μ κ²€)

### μ°Έκ³  λ΅κ·Έ
- "ID μ»¬λΌ ν¬ν•¨: id"κ°€ λ΅κ·Έμ— μ¶λ ¥λλ©΄ μ •μƒμ μΌλ΅ id μ»¬λΌμ΄ feature setμ— ν¬ν•¨λ κ²ƒ
- SMOTE μ μ© μ „ν›„ ν΄λμ¤ λ¶„ν¬κ°€ λ™μΌν•λ©΄ μ—¬μ „ν SMOTEκ°€ λ™μ‘ν•μ§€ μ•λ” κ²ƒ (κ²°μΈ΅μΉ λ“± μ¶”κ°€ μ κ²€ ν•„μ”)

## λ‹¤μ λ‹¨κ³„
ν„μ¬ Phase 5-4 (κ³ κΈ‰ λ¨λΈ κ°λ° λ° ν™•μ¥) μ§„ν–‰ μ¤‘ β…
- **μ™„λ£**: CatBoost, LightGBM, Random Forest λ¨λΈ κµ¬ν„ λ° ν…μ¤νΈ (4κ° λ¨λΈ μ™„λ£)
- **μ™„λ£**: ConfigManager κΈ°λ° λ¦¬μƒν”λ§ λΉ„κµ μ‹¤ν— κµ¬ν„ λ° λ¨λ“  λ¨λΈ ν…μ¤νΈ μ™„λ£
- **μ™„λ£**: μ«μ κ²€μ¦ μ ν‹Έλ¦¬ν‹° ν•¨μ μ¶”κ°€λ΅ ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ•μ •μ„± ν–¥μƒ
- **μ™„λ£**: λ¦¬μƒν”λ§ ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹μ¤ν… λ€ν­ κ°μ„  (2025-07-16)
- **μ™„λ£**: NaN/Inf λ°μ΄ν„° ν’μ§ κ²€μ¦ λ° data_analysis.py ν™•μ¥ (2025-07-16)
- **μ§„ν–‰ μ¤‘**: μ•™μƒλΈ” λ¨λΈ κ°λ° (Stacking, Blending, Voting)
- **μμ •**: ν”Όμ² μ—”μ§€λ‹μ–΄λ§ κ³ λ„ν™”, λ¨λΈ ν•΄μ„ λ° μ„¤λ… κ°€λ¥μ„± ν™•λ³΄

## μ°Έκ³  λ¬Έμ„
- `PROJECT_PROGRESS.md`: μƒμ„Έν• μ§„ν–‰ μƒν™© λ° λ¶„μ„ κ²°κ³Ό
- `projectplan`: μ „μ²΄ ν”„λ΅μ νΈ κ³„νμ„
- `NEXT_PHASE_PLAN.md`: λ‹¤μ λ‹¨κ³„ μƒμ„Έ κ³„ν

## κΈ°μ  μ¤νƒ
- **Python**: 3.10.18
- **μ£Όμ” λΌμ΄λΈλ¬λ¦¬**: pandas, numpy<2, matplotlib, seaborn, mlflow, scikit-learn, xgboost==1.7.6, catboost, lightgbm, optuna
- **ν™κ²½ κ΄€λ¦¬**: conda
- **μ½”λ“ ν’μ§**: PEP 8 μ¤€μ, λ¨λ“ν™”, λ¬Έμ„ν™”, μ•μ •μ„± ν™•λ³΄ 