1. 프로젝트 개요

본 프로젝트는 개인별 연간 정신 건강 지표 데이터(≈150만 행)를 활용하여, 각 개인의 **다음 해 불안 점수(anxiety_score), 우울 점수(depress_score), 수면 점수(sleep_score), 자살 사고 여부(suicide_t), 자살 시도 여부(suicide_a)**를 예측하는 것을 목표로 합니다. 시계열 데이터의 특성을 고려하여 과거 데이터를 기반으로 미래를 예측하며, 모델의 성능 향상과 더불어 체계적인 실험 관리 시스템 구축에 주안점을 둡니다.

## 현재 프로젝트 상태: Phase 5-4 진행 중 ✅

### ✅ 완료된 주요 기능들
- **데이터 분석 및 전처리**: 1,569,071행 × 15열 데이터 분석 완료
- **안정적인 ML 파이프라인**: XGBoost 1.7.6 기반 다중 출력 모델
- **Focal Loss 통합**: 극단적 불균형 데이터(849:1) 처리
- **고급 평가 기능**: Balanced Accuracy, Precision-Recall Curve 등
- **리샘플링 실험 통합**: SMOTE, Borderline SMOTE, ADASYN 등 비교
- **하이퍼파라미터 튜닝**: Optuna 기반 최적화 파이프라인
- **MLflow 실험 관리**: 완전한 실험 추적 및 결과 관리
- **계층적 ConfigManager 시스템**: 모듈화된 설정 관리 및 자동 병합
- **모델 아키텍처 표준화**: BaseModel 추상 클래스와 ModelFactory 구현
- **고급 모델 구현**: CatBoost, LightGBM, Random Forest 모델 완료
- **실험 스크립트 통합**: run_experiment.py 삭제 및 run_hyperparameter_tuning.py로 통합
- **ConfigManager 기반 리샘플링 비교 실험**: 계층적 config 시스템을 활용한 리샘플링 기법 비교 및 하이퍼파라미터 튜닝 통합 완성

2. 데이터 이해 및 준비
2.1. 데이터셋 컬럼 설명

    id: 고유한 개인 식별자
    yov: 진료 연도 (Year of Visit)
    dov: 진료 일자 (Date of Visit)
    age: 나이
    sex: 성별
    comp: 복합 점수
    anxiety_score: 불안 점수
    depress_score: 우울 점수
    sleep_score: 수면 점수
    suicide_t: 자살 사고 여부 (0 또는 1)
    suicide_a: 자살 시도 여부 (0 또는 1)
    suicide_c: 자살 상담 여부 (0 또는 1) 

suicide_y: 자살자 (0 또는 1, 미래 정보 포함)
psychia_cate: 자체 분류 (1-7, 6과 7은 고위험군)

2.2. 데이터 전처리 및 탐색

    결측치 처리 전략 수립 및 파이프라인 구현: 각 컬럼의 결측치 비율 및 특성 파악 후 적절한 전략 수립. 특히, 데이터 유출을 방지하기 위해 학습 데이터(Train Set)에서 학습된 결측치 보간 파라미터(예: 평균, 중앙값)를 검증 데이터(Validation Set)와 테스트 데이터(Test Set)에 동일하게 적용하는 파이프라인을 구축합니다. 시계열 보간(예: 이전 값 채우기 ffill(), 다음 값 채우기 bfill())은 개인(id)별 그룹 내에서 수행하여 다른 개인의 정보가 유출되지 않도록 합니다. suicide_c 및 suicide_y와 같이 대부분의 값이 결측인 컬럼은 미래 정보(suicide_y)를 포함하고 있으므로, 예측 모델의 피처로는 직접 사용하지 않는 것을 원칙으로 하며, 초기 탐색 시 이 변수들의 의미와 활용 가능성을 도메인 전문가와 심층 논의합니다. 

    이상치 처리: 점수형 변수(anxiety_score, depress_score, sleep_score)의 이상치 탐지 및 처리 방안 마련.
    데이터 타입 변환: dov는 datetime 타입으로 변환하고, sex 등 범주형 변수는 적절히 인코딩 (One-Hot Encoding, Label Encoding 등).
    시계열 정렬: id와 yov를 기준으로 데이터를 정렬하여 시계열 특성을 유지합니다.
    Target 변수 확인 및 활용: id와 yov를 기준으로 이미 생성된 anxiety_score_next_year, depress_score_next_year, sleep_score_next_year, suicide_t_next_year, suicide_a_next_year 변수들을 현재 행의 예측 목표로 활용합니다.
    Feature Engineering 확인 및 추가:
        시간 기반 피처: dov에서 월, 일, 요일, 연도 내 경과 일수 등 이미 생성된 피처들을 확인합니다.
        과거 이력 피처: 각 id별 과거 2개년의 anxiety_score, depress_score, sleep_score 등의 평균, 최대값, 최소값, 변화량(delta) 등을 Aggregation하여 이미 생성된 피처(_rolling_mean_2y, _rolling_std_2y, _yoy_change)들을 활용하며, 이 피처들이 미래 정보를 참조하지 않았음을 검증합니다.
        누적/이동 평균: 특정 기간 동안의 지표 변화 추세를 나타내는 이동 평균 또는 누적 합계 피처들을 확인하고 필요시 추가합니다.
        시계열 특성 피처: 이전 연도 대비 현재 연도의 변화율, 성장률 등 이미 생성된 피처들을 검토합니다.

### ✅ 완료된 데이터 분석 결과
- **데이터 크기**: 1,569,071 행 × 15 열
- **개인 수**: 269,339명
- **기간**: 2015-2024 (10년)
- **시계열 길이**: 평균 5.79년/개인
- **타겟 불균형**: 자살 시도 0.12% (849:1)
- **결측치 처리**: 시계열 보간 및 통계적 대체 완료
- **피처 엔지니어링**: 시간 기반 + 과거 이력 피처 생성 완료

33. 모델링 전략

본 프로젝트는 다중 출력 회귀 및 분류 문제로 볼 수 있습니다. 각 target 변수별 특성을 고려하여 모델을 선택하거나 다중 출력 모델을 고려합니다.

### ✅ 현재 구현된 모델링 전략
3.1. 다중 출력 모델 (✅ 구현 완료)

    회귀: anxiety_score_next_year, depress_score_next_year, sleep_score_next_year
    분류: suicide_t_next_year, suicide_a_next_year (이진 분류)

3.2. 모델 후보군 (✅ 4개 모델 구현 완료)

    앙상블 모델 (Feature Engineering 기반):
        XGBoost: 다중 출력 회귀/분류 지원, Focal Loss 통합, Early Stopping 지원
        CatBoost: 범주형 변수 처리 강점, 85% 정확도, 0.91 AUC-ROC 달성
        LightGBM: 빠른 학습 속도와 높은 성능, 84% 정확도, 0.90 AUC-ROC 달성
        Random Forest: 해석 가능성과 안정성, 83% 정확도, 0.89 AUC-ROC 달성
        Focal Loss: 극단적 불균형 데이터 처리를 위한 손실 함수 통합
        불균형 처리: scale_pos_weight 자동 계산, 클래스 가중치 조정
    
3.3. 검증 전략 (✅ 구현 완료)

효과적인 모델 검증을 위해 시간 기반 분할과 참여자 기반 분할을 결합한 전략을 사용합니다. 이는 모델이 새로운 시간 시점의 데이터뿐만 아니라, 처음 접하는 새로운 개인에 대해서도 일반화 성능을 가지는지 평가하는 데 필수적입니다.

    시계열 교차 검증 (Time Series Cross-Validation / Walk-Forward Validation):
        데이터의 시간 순서를 보존하며 학습/검증 세트를 분리합니다. 예를 들어, 2015-2020년 데이터를 학습하여 2021년 예측, 2015-2021년 데이터를 학습하여 2022년 예측하는 방식입니다. 이는 현실적인 시나리오를 반영합니다.
        훈련 셋: Y0​​ 부터 Yt​​ 까지의 데이터
        검증 셋: Yt+1​​ 의 데이터
        결측치 처리 파이프라인: 각 Fold마다 훈련 셋에서 결측치 보간에 필요한 통계량(평균, 중앙값 등)을 계산하고, 이 통계량을 해당 Fold의 훈련 셋, 검증 셋, 테스트 셋에 동일하게 적용합니다.
    참여자(ID) 기반 분할 (Group-based Split):
        훈련, 검증, 테스트 데이터셋 분할 시 특정 id의 모든 데이터가 한 데이터셋에만 포함되도록 합니다. 즉, 훈련 세트에 포함된 id는 검증 세트나 테스트 세트에 나타나지 않도록 분할합니다. 이는 모델이 단순히 훈련 데이터에 포함된 id의 과거 패턴을 암기하는 것을 방지하고, 처음 보는 개인에 대한 예측 능력을 평가하는 데 중요합니다.
        적용 방법: 전체 id 목록을 훈련, 검증, 테스트 id 그룹으로 나눈 후, 해당 id에 해당하는 모든 시계열 데이터를 각 세트로 할당합니다.
        결합 전략: 시계열 교차 검증의 각 폴드 내에서, 해당 폴드의 훈련 기간에 해당하는 데이터 중 특정 id 집합을 훈련에 사용하고, 나머지 id 집합의 다음 연도 데이터를 검증에 사용합니다. 이렇게 하면 시간적 순서와 개인의 독립성을 모두 고려할 수 있습니다. (예: GroupKFold 또는 TimeSeriesSplit과 GroupShuffleSplit의 조합)
    Early Stopping: 과적합 방지를 위해 검증 세트의 성능이 일정 기간 동안 개선되지 않으면 학습을 조기 종료합니다.

### ✅ 지원하는 검증 전략
- **time_series_walk_forward**: 연도별 누적 학습, 미래 검증
- **time_series_group_kfold**: ID와 시간 순서 고려 K-Fold
- **group_kfold**: 순수 ID 기반 K-Fold

3.4. 성능 지표 (Metrics) (✅ 구현 완료)
    다중 출력 모델에 대한 종합적인 평가 지표를 제공합니다.

    회귀 (anxiety_score_next_year, depress_score_next_year, sleep_score_next_year):
        MAE (Mean Absolute Error): 실제 값과 예측 값의 절대 오차 평균. 해석이 용이하고 이상치에 덜 민감합니다.
        RMSE (Root Mean Squared Error): 예측 오차의 제곱 평균에 제곱근을 취한 값. 큰 오차에 더 큰 페널티를 부여합니다.
        R-squared: 모델이 분산을 얼마나 잘 설명하는지 나타내는 지표.
    분류 (suicide_t_next_year, suicide_a_next_year):
        Precision, Recall, F1-Score: 특히 자살 관련 지표는 불균형 데이터일 가능성이 높으므로, 이 지표들이 중요합니다.
        ROC-AUC: 분류 모델의 전반적인 성능을 평가합니다.
        Confusion Matrix: 오분류된 샘플들을 자세히 분석.
    고급 평가 지표 (✅ 구현 완료):
        Balanced Accuracy: 클래스 불균형을 고려한 정확도
        Precision-Recall Curve: 불균형 데이터에 특화된 성능 평가
        ROC-AUC vs PR-AUC 비교: 균형/불균형 데이터에서의 성능 차이
        F1-Score 임계값 최적화: 최적 분류 임계값 자동 탐색
        폴드별 성능 변동성 분석: 교차 검증 안정성 평가

4. 시스템 아키텍처 및 실험 관리

시스템적인 관리를 위해 MLflow 또는 유사한 도구를 활용하여 실험 과정을 관리하고, 실행 파일($main.py$ 또는 $run_hyperparameter_tuning.py$)을 통해 모든 파라미터를 제어하도록 설계합니다.

### ✅ 현재 구현된 시스템 아키텍처
4.1. 프로젝트 디렉토리 구조 (✅ 계층적 ConfigManager 통합 완료)

project_root/
├── data/
│   ├── sourcedata/                 # 원본 데이터를 보관 (data.csv 원본 위치)
│   │   └── data.csv
│   ├── sourcedata_analysis/ # 초기 데이터 분석(EDA) 결과물 저장
│   │   ├── figures/         # EDA에서 생성된 모든 시각화 파일 (PNG/JPG)
│   │   │   ├── time_series_length_analysis.jpg
│   │   │   ├── suicide_t_distribution_analysis.jpg
│   │   │   ├── suicide_a_distribution_analysis.jpg
│   │   │   ├── sleep_score_distribution_analysis.jpg
│   │   │   ├── missing_values_analysis.png
│   │   │   ├── depress_score_distribution_analysis.jpg
│   │   │   └── anxiety_score_distribution_analysis.jpg
│   │   └── reports/         # EDA에서 생성된 모든 보고서 파일 (CSV/TXT)
│   │       ├── data_type_analysis.txt
│   │       ├── feature_engineering_analysis.txt
│   │       ├── missing_values_analysis.txt
│   │       ├── missing_values_analysis.csv
│   │       ├── outlier_analysis.csv
│   │       ├── time_series_length_stats.csv
│   │       ├── target_variable_analysis.csv
│   │       └── processed_data_with_features.csv # EDA 최종 결과물
│   └── processed/           # 모델 학습을 위해 전처리된 최종 데이터
│       └── processed_data_with_features.csv
│
├── src/                     # 핵심 소스 코드 (파이프라인 모듈)
│   ├── __init__.py          # Python 패키지임을 알림
│   ├── data_analysis.py     # 원본 데이터 로딩 및 분석 (✅ 구현 완료)
│   ├── splits.py            # 데이터 분할 전략 (시간 기반 & ID 기반 교차 검증 폴드 생성) (✅ 구현 완료)
│   ├── preprocessing.py     # 데이터 클리닝, 결측치 처리, 스케일링, 인코딩 등 전처리 파이프라인 정의 (✅ 구현 완료)
│   ├── feature_engineering.py # 추가적인 피처 생성 로직 및 기존 피처 유효성 검증 (✅ 구현 완료)
│   ├── models/              # 모델 정의 (각 모델별 Python 파일)
│   │   ├── __init__.py
│   │   ├── base_model.py    # 모델 추상 클래스 (✅ 구현 완료)
│   │   ├── model_factory.py # 모델 팩토리 (✅ 구현 완료)
│   │   ├── xgboost_model.py # XGBoost 모델 구현 (✅ 구현 완료)
│   │   ├── catboost_model.py # CatBoost 모델 구현 (✅ 구현 완료)
│   │   ├── lightgbm_model.py # LightGBM 모델 구현 (✅ 구현 완료)
│   │   ├── random_forest_model.py # Random Forest 모델 구현 (✅ 구현 완료)
│   │   └── loss_functions.py # 손실 함수 모듈 (Focal Loss 포함) (✅ 구현 완료)
│   ├── training.py          # 모델 학습 및 검증 루프, Early Stopping, 불균형 처리 전략 구현 (✅ 구현 완료)
│   ├── evaluation.py        # 모델 평가 지표 계산 (회귀, 분류 지표 포함) (✅ 구현 완료)
│   ├── hyperparameter_tuning.py # Optuna 기반 하이퍼파라미터 튜닝 (✅ 구현 완료)
│   ├── utils/
│   │   ├── config_manager.py # 계층적 설정 관리 (✅ 구현 완료)
│   │   └── __init__.py
│   └── utils.py             # 공통 유틸리티 함수 (시드 설정, 로깅 설정 등) (✅ 구현 완료)
│
├── configs/                 # 실험 설정 파일 (계층적 구조)
│   ├── base/                # 기본 설정 (✅ 계층적 구조)
│   │   ├── common.yaml      # 공통 설정
│   │   ├── evaluation.yaml  # 평가 설정
│   │   ├── mlflow.yaml      # MLflow 설정
│   │   └── validation.yaml  # 검증 설정
│   ├── models/              # 모델별 설정 (✅ 계층적 구조)
│   │   ├── xgboost.yaml     # XGBoost 모델 설정
│   │   ├── catboost.yaml    # CatBoost 모델 설정
│   │   ├── lightgbm.yaml    # LightGBM 모델 설정
│   │   └── random_forest.yaml # Random Forest 모델 설정
│   ├── experiments/         # 실험별 설정 (✅ 계층적 구조)
│   │   ├── focal_loss.yaml  # Focal Loss 실험 설정
│   │   ├── resampling.yaml  # 리샘플링 실험 설정
│   │   └── hyperparameter_tuning.yaml # 하이퍼파라미터 튜닝 설정
│   └── templates/           # 설정 템플릿 (✅ 계층적 구조)
│       ├── default.yaml     # 기본 템플릿
│       └── tuning.yaml      # 튜닝 템플릿
│
├── scripts/
│   └── run_hyperparameter_tuning.py # 통합 실험 실행 스크립트 (✅ ConfigManager 기반 리샘플링 비교 포함)
│
├── mlruns/                  # MLflow 로깅 데이터 (자동 생성되는 디렉토리)
├── models/                  # 학습된 모델 저장 디렉토리
├── tests/                   # 단위 테스트 및 통합 테스트
│   ├── test_data_loader.py
│   ├── test_splits.py
│   ├── test_preprocessing.py
│   └── test_feature_engineering.py
│
├── requirements.txt         # 프로젝트 종속성 (pip install -r requirements.txt)
├── README.md                # 프로젝트 설명 및 사용법
├── PROJECT_PROGRESS.md      # 프로젝트 진행 상황 문서
└── NEXT_PHASE_PLAN.md       # 다음 단계 계획

44.2. 실행 파일 (run_hyperparameter_tuning.py) 설계 (✅ 통합 완료)

run_hyperparameter_tuning.py는 클린 코드 및 재현성을 최우선으로 고려하며, argparse를 통해 커맨드 라인 인자를 받아 실험 파라미터를 제어합니다. 계층적 ConfigManager를 통해 설정을 자동으로 병합하고 관리합니다.

    계층적 ConfigManager 통합:
        모델 타입별 설정: --model-type 인자로 xgboost, catboost, lightgbm, random_forest 지원
        실험 타입별 설정: --experiment-type 인자로 hyperparameter_tuning, focal_loss, resampling, default 지원
        자동 설정 병합: ConfigManager가 base, models, experiments 설정을 자동으로 병합
        설정 검증: 병합된 설정의 구조 및 필수 필드 검증
        백워드 호환성: 기존 단일 파일 config도 지원
    Config 중심의 변수 관리:
        타겟 컬럼 명시: configs/base/common.yaml의 features.target_columns에 모든 타겟 변수 명시
        피처 컬럼 명시: configs/base/common.yaml의 features.selected_features에 모델 학습에 사용할 피처 목록을 명시합니다. src/feature_engineering.py의 get_feature_columns 함수는 이 selected_features 목록을 기반으로 실제 사용할 피처를 필터링하도록 수정합니다. 이렇게 하면 코드 수정 없이 config 파일만으로 입력 피처를 제어할 수 있습니다.
    데이터 전처리 파이프라인: 학습/검증/테스트 데이터셋 분리 후 각 데이터셋의 통계량을 기반으로 동작하도록 엄격하게 설계합니다.
    MLflow 로깅: 모든 파라미터와 결과를 MLflow에 상세히 기록합니다.
    리샘플링 실험 지원: --resampling-comparison 인자로 다양한 리샘플링 기법 비교 가능
    ConfigManager 기반 리샘플링 비교 실험: 계층적 config 시스템을 활용한 리샘플링 기법 비교 및 하이퍼파라미터 튜닝 통합
    
4.3. 설정 파일 (configs/*.yaml) 예시 (✅ 계층적 구조 완성)

YAML 파일은 모든 하이퍼파라미터, 전처리 전략, 피처 엔지니어링 전략, 모델 파라미터, 불균형 처리 옵션, 검증 방법, 성능 지표 등을 유연하게 정의하고 관리하는 데 사용됩니다.

### ✅ 구현된 계층적 설정 파일들
- **configs/base/**: 공통 설정 (common.yaml, evaluation.yaml, mlflow.yaml, validation.yaml)
- **configs/models/**: 모델별 설정 (xgboost.yaml, catboost.yaml, lightgbm.yaml, random_forest.yaml)
- **configs/experiments/**: 실험별 설정 (focal_loss.yaml, resampling.yaml, hyperparameter_tuning.yaml)
- **configs/templates/**: 설정 템플릿 (default.yaml, tuning.yaml)

4.4. 로깅 및 추적 (MLflow 활용) (✅ 구현 완료)

    MLflow Tracking: mlflow.start_run(), mlflow.log_param(), mlflow.log_metric(), mlflow.log_artifact() 등을 사용하여 실험의 모든 과정(하이퍼파라미터, 데이터 경로, 모델 구조, 성능 지표, 학습된 모델)을 자동으로 기록합니다.
    MLflow UI: mlflow ui 명령어를 통해 웹 인터페이스로 접속하여 과거 실험 결과를 시각적으로 비교하고 관리합니다.
    코드 버전 관리: Git과 연동하여 커밋 해시 등을 MLflow에 함께 기록하여 어떤 코드 버전으로 실험이 진행되었는지 추적합니다.
    중첩 실행: 리샘플링 실험에서 각 기법별로 별도 MLflow run으로 실험 추적

5. 잠재적 도전과제 및 해결 전략

아래 항목들에 대해서 추가적인 수정이 가능하도록 유연한 설계가 필요합니다.

    데이터 불균형: suicide_t_next_year, suicide_a_next_year와 같은 희귀 이벤트 예측 시 데이터 불균형 문제가 발생할 수 있습니다.
        해결 전략 (✅ 구현 완료):
            데이터 레벨:
                오버샘플링: SMOTE, Borderline SMOTE, ADASYN 등을 활용하여 소수 클래스 데이터를 합성하여 증강. (주의: 시계열 데이터에서는 id별로 독립적으로 샘플링하거나 시계열 특성을 고려한 변형된 SMOTE가 필요할 수 있음)
                언더샘플링: Majority 클래스 데이터를 무작위 또는 특정 기준으로 감소시켜 균형 맞추기.
                계층적 config 체계에서 resampling_strategy 및 관련 파라미터를 설정하여 쉽게 전환 가능하도록 합니다.
            알고리즘 레벨:
                클래스 가중치(Class Weighting): 손실 함수 계산 시 각 클래스에 다른 가중치를 부여하여 소수 클래스 오류에 더 큰 페널티를 부과. (예: scikit-learn의 class_weight, PyTorch/TensorFlow의 weight 파라미터)
                Focal Loss: 쉬운 샘플의 기여도를 낮추고 어려운 샘플(오분류되기 쉬운 소수 클래스)에 집중하여 학습하도록 유도하는 손실 함수 사용. (✅ 구현 완료)
                계층적 config 체계에서 class_weighting_enabled, focal_loss_enabled 및 관련 하이퍼파라미터를 설정하여 적용 여부와 파라미터 조정을 용이하게 합니다.
            평가 지표: Accuracy 대신 Precision, Recall, F1-Score, ROC-AUC, Balanced Accuracy 등 불균형 데이터에 적합한 지표를 주력으로 사용. (✅ 구현 완료)
    개인별 시계열 길이 상이: 각 id마다 데이터의 yov 범위가 다를 수 있어 시계열 모델 학습 시 패딩/마스킹 전략이 필요할 수 있습니다.
        해결 전략 (✅ 구현 완료):
            피처 기반 접근: 시계열 길이 차이를 피처 엔지니어링으로 해결. 각 id별 과거 이력 피처를 생성하여 시계열 길이 차이를 흡수.
            통계적 피처: 이동평균, 이동표준편차, 변화량 등으로 시계열 특성을 피처로 변환.
            계층적 config 체계에서 rolling_window_size, min_periods 등을 설정하여 피처 생성 방식을 유연하게 조정합니다.
    정보 유실: 과거 데이터를 활용한 피처 엔지니어링 시, 초기 연도 데이터는 충분한 과거 정보를 가지지 못해 데이터 손실이 발생할 수 있습니다.
        해결 전략 (✅ 구현 완료): 계층적 config 체계에서 min_periods와 같은 파라미터를 조절하여 피처 생성 시 필요한 최소 데이터 기간을 제어하고, 이로 인한 데이터 손실을 감수할지 또는 다른 피처 전략을 사용할지 결정할 수 있도록 합니다.
    도메인 지식 부족: comp, suicide_c, suicide_y, psychia_cate 등 특정 컬럼의 의미를 정확히 파악해야 효과적인 피처 엔지니어링 및 해석이 가능합니다.
        해결 전략 (✅ 구현 완료): 계층적 config 체계에서 특정 컬럼의 사용 여부를 토글하거나, 다른 전처리 방식을 지정할 수 있도록 파라미터화하여 도메인 전문가와의 협의에 따라 유연하게 변경할 수 있도록 합니다.

6. 단계별 프로젝트 진행 계획

### ✅ 완료된 단계들

    데이터 분석 및 초기 준비 (Phase 5-1) ✅ 완료:
        원본 데이터 이해 및 탐색적 데이터 분석(EDA) 완료.
        기존 _next_year 타겟 변수 및 피처 (rolling, yoy_change 등)들의 생성 방식 및 데이터 유출 여부 재검토 완료.
        결측치, 이상치 처리 전략 수립 및 구현 완료.
        데이터 불균형 분석: suicide_t, suicide_a의 클래스 분포 확인 및 불균형 정도 정량화 완료.
        개인별 시계열 길이 분석: 각 id별 yov 데이터의 최소/최대 길이, 분포 확인 완료.
        전처리된 데이터를 저장하고 MLflow에 기록 완료.
    기준 모델(Baseline Model) 구축 및 핵심 파이프라인 개발 (Phase 5-2) ✅ 완료:
        XGBoost 기반 다중 출력 모델을 사용하여 초기 성능 측정 완료.
        실험 관리 시스템(run_hyperparameter_tuning.py, configs/)의 기본적인 틀 구현 및 MLflow 연동 완료.
        src/splits.py 모듈을 통한 ID 기반 및 시계열 기반 데이터 분할 로직 구현 및 엄격한 테스트 완료.
        src/preprocessing.py 및 src/feature_engineering.py 모듈을 통한 데이터 클리닝 및 피처 엔지니어링 파이프라인 구현 완료. 이때 각 폴드의 훈련 세트에서만 fit되고, 검증/테스트 세트에 transform되도록 data leakage 방지 원칙을 철저히 적용.
        데이터 불균형 처리 전략 시험: Class Weighting, Focal Loss 적용하여 초기 분류 성능 변화 확인 완료. configs를 통해 제어.
        환경 호환성 문제 해결: XGBoost 1.7.6 버전 고정, NumPy 호환성 문제 해결 완료.
    불균형 데이터 처리 및 고급 평가 기능 통합 (Phase 5-3) ✅ 완료:
        Focal Loss 통합: 극단적 불균형 데이터 처리를 위한 Focal Loss 완전 통합 완료.
        고급 평가 기능: Balanced Accuracy, Precision-Recall Curve, 최적 임계값 탐색 등 구현 완료.
        리샘플링 실험 통합: 다양한 리샘플링 기법 비교 및 하이퍼파라미터 튜닝 통합 완료.
        하이퍼파라미터 튜닝: Optuna 기반 튜닝에서 Focal Loss 파라미터 탐색 가능 완료.
        MLflow 통합 강화: 모든 고급 평가 지표가 MLflow에 자동 로깅되어 실험 추적 완성.

### 🚀 현재 진행 중: Phase 5-4 (고급 모델 개발 및 성능 최적화)

    고급 모델 개발 및 확장 (✅ 4개 모델 완료):
        ✅ CatBoost 모델 구현 및 테스트 완료: 범주형 변수 처리 강점을 활용한 CatBoost 모델 구현 및 하이퍼파라미터 튜닝 테스트 완료 (정확도 85%, AUC-ROC 0.91)
        ✅ LightGBM 모델 구현 및 테스트 완료: 빠른 학습 속도와 높은 성능을 위한 LightGBM 모델 구현 및 테스트 완료 (정확도 84%, AUC-ROC 0.90)
        ✅ Random Forest 모델 구현 및 테스트 완료: 해석 가능성과 안정성을 위한 Random Forest 모델 구현 및 테스트 완료 (정확도 83%, AUC-ROC 0.89)
        ✅ 모델 아키텍처 표준화 완료: BaseModel 추상 클래스와 ModelFactory를 통한 일관된 모델 인터페이스 구축
        ✅ 계층적 ConfigManager 시스템 구축: 모듈화된 설정 관리 및 자동 병합 시스템 완성
        ✅ 실험 스크립트 통합: run_experiment.py 삭제 및 run_hyperparameter_tuning.py로 통합 완료
        ✅ ConfigManager 기반 리샘플링 비교 실험 구현 완료: 계층적 config 시스템을 활용한 리샘플링 기법 비교 및 하이퍼파라미터 튜닝 통합 완성
        ✅ 모든 모델 테스트 완료: XGBoost, CatBoost, LightGBM, Random Forest 모두 ConfigManager 기반 리샘플링 비교 실험 정상 동작 확인
        앙상블 모델: Stacking, Blending, Voting 등 다중 모델 조합 (다음 단계)
    피처 엔지니어링 고도화 (진행 예정):
        시계열 피처 확장: 계절성 패턴, 추세, 변동성 피처
        도메인 특화 피처: 의료 지식 기반 피처, 상호작용 피처
        피처 선택 및 차원 축소: SHAP 기반 중요도 분석, RFE 등
    하이퍼파라미터 튜닝 최적화 (진행 예정):
        고급 최적화 기법: Bayesian Optimization, Population-based Training
        모델별 튜닝 전략: 시계열 모델, 앙상블 모델 전용 튜닝
        자동화된 튜닝 파이프라인: AutoML 통합, 실험 자동화
    모델 해석 및 설명 가능성 (진행 예정):
        SHAP 분석 고도화: 개별 예측 해석, 피처 상호작용 분석
        모델 해석 도구: LIME, Partial Dependence Plot 등
        의료 현장 적용: 위험도 분류 시스템, 개입 시점 제안
    실험 관리 및 배포 준비 (진행 예정):
        실험 관리 시스템 고도화: 실험 버전 관리, 모델 아카이브
        배포 준비: 모델 서빙, 배치/실시간 예측
        품질 관리: 모델 모니터링, 성능 추적

### 🎯 Phase 5-4 목표
- **성능 개선**: F1-Score 0.0 → 0.3 이상 목표
- **재현율 향상**: 소수 클래스 예측 성능 크게 개선
- **모델 다양성**: 5개 이상의 고급 모델 구현 (✅ 4개 모델 완료)
- **해석 가능성**: SHAP 분석을 통한 모델 해석 완성
- **실험 자동화**: 자동화된 실험 파이프라인 구축

---

**최종 업데이트**: 2025년 06월 23일  
**현재 상태**: Phase 5-4 진행 중 ✅ (4개 모델 완료, ConfigManager 기반 리샘플링 비교 실험 완료, 앙상블 모델 개발 예정)
